{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('default of credit card clients.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X and Y distribution of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.iloc[:, 1:24].values\n",
    "y = dataset.iloc[:, 24].values\n",
    "X.shape,y.shape\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 23)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086723</td>\n",
       "      <td>0.160138</td>\n",
       "      <td>0.080648</td>\n",
       "      <td>0.260979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>0.163220</td>\n",
       "      <td>0.084074</td>\n",
       "      <td>0.263485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.080808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.224138</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093789</td>\n",
       "      <td>0.173637</td>\n",
       "      <td>0.095470</td>\n",
       "      <td>0.272928</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.009458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113407</td>\n",
       "      <td>0.186809</td>\n",
       "      <td>0.109363</td>\n",
       "      <td>0.283685</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.001892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106020</td>\n",
       "      <td>0.179863</td>\n",
       "      <td>0.099633</td>\n",
       "      <td>0.275681</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.021779</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.001284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200746</td>\n",
       "      <td>0.243036</td>\n",
       "      <td>0.111622</td>\n",
       "      <td>0.273259</td>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.001892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0.141414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088267</td>\n",
       "      <td>0.168596</td>\n",
       "      <td>0.085794</td>\n",
       "      <td>0.260979</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.010042</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087859</td>\n",
       "      <td>0.179805</td>\n",
       "      <td>0.101057</td>\n",
       "      <td>0.275854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024552</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.005864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0.070707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128239</td>\n",
       "      <td>0.209850</td>\n",
       "      <td>0.092403</td>\n",
       "      <td>0.298591</td>\n",
       "      <td>0.098334</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.124174</td>\n",
       "      <td>0.003412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113667</td>\n",
       "      <td>0.194553</td>\n",
       "      <td>0.112803</td>\n",
       "      <td>0.272746</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.001892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0    1         2         3         4    5    6    7    8    9   \\\n",
       "0      0.010101  1.0  0.333333  0.333333  0.051724  0.4  0.4  0.1  0.1  0.0   \n",
       "1      0.111111  1.0  0.333333  0.666667  0.086207  0.1  0.4  0.2  0.2  0.2   \n",
       "2      0.080808  1.0  0.333333  0.666667  0.224138  0.2  0.2  0.2  0.2  0.2   \n",
       "3      0.040404  1.0  0.333333  0.333333  0.275862  0.2  0.2  0.2  0.2  0.2   \n",
       "4      0.040404  0.0  0.333333  0.333333  0.620690  0.1  0.2  0.1  0.2  0.2   \n",
       "...         ...  ...       ...       ...       ...  ...  ...  ...  ...  ...   \n",
       "29995  0.212121  0.0  0.500000  0.333333  0.310345  0.2  0.2  0.2  0.2  0.2   \n",
       "29996  0.141414  0.0  0.500000  0.666667  0.379310  0.1  0.1  0.1  0.1  0.2   \n",
       "29997  0.020202  0.0  0.333333  0.666667  0.275862  0.6  0.5  0.4  0.1  0.2   \n",
       "29998  0.070707  0.0  0.500000  0.333333  0.344828  0.3  0.1  0.2  0.2  0.2   \n",
       "29999  0.040404  0.0  0.333333  0.333333  0.431034  0.2  0.2  0.2  0.2  0.2   \n",
       "\n",
       "       ...        13        14        15        16        17        18  \\\n",
       "0      ...  0.086723  0.160138  0.080648  0.260979  0.000000  0.000409   \n",
       "1      ...  0.087817  0.163220  0.084074  0.263485  0.000000  0.000594   \n",
       "2      ...  0.093789  0.173637  0.095470  0.272928  0.001738  0.000891   \n",
       "3      ...  0.113407  0.186809  0.109363  0.283685  0.002290  0.001199   \n",
       "4      ...  0.106020  0.179863  0.099633  0.275681  0.002290  0.021779   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "29995  ...  0.200746  0.243036  0.111622  0.273259  0.009730  0.011875   \n",
       "29996  ...  0.088267  0.168596  0.085794  0.260979  0.002103  0.002094   \n",
       "29997  ...  0.087859  0.179805  0.101057  0.275854  0.000000  0.000000   \n",
       "29998  ...  0.128239  0.209850  0.092403  0.298591  0.098334  0.002024   \n",
       "29999  ...  0.113667  0.194553  0.112803  0.272746  0.002379  0.001069   \n",
       "\n",
       "             19        20        21        22  \n",
       "0      0.000000  0.000000  0.000000  0.000000  \n",
       "1      0.001116  0.001610  0.000000  0.003783  \n",
       "2      0.001116  0.001610  0.002345  0.009458  \n",
       "3      0.001339  0.001771  0.002506  0.001892  \n",
       "4      0.011160  0.014493  0.001615  0.001284  \n",
       "...         ...       ...       ...       ...  \n",
       "29995  0.005583  0.004907  0.011723  0.001892  \n",
       "29996  0.010042  0.000208  0.000000  0.000000  \n",
       "29997  0.024552  0.006763  0.004689  0.005864  \n",
       "29998  0.001315  0.003101  0.124174  0.003412  \n",
       "29999  0.001596  0.001610  0.002345  0.001892  \n",
       "\n",
       "[30000 rows x 23 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "df = pd.DataFrame(x_scaled)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.11111111e-01, 1.00000000e+00, 3.33333333e-01, 6.66666667e-01,\n",
       "       8.62068966e-02, 1.00000000e-01, 4.00000000e-01, 2.00000000e-01,\n",
       "       2.00000000e-01, 2.00000000e-01, 4.00000000e-01, 1.48892434e-01,\n",
       "       6.78575089e-02, 8.78171337e-02, 1.63219937e-01, 8.40739510e-02,\n",
       "       2.63484742e-01, 0.00000000e+00, 5.93732912e-04, 1.11602161e-03,\n",
       "       1.61030596e-03, 0.00000000e+00, 3.78310691e-03])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.11111111e-01, 1.00000000e+00, 3.33333333e-01, 6.66666667e-01,\n",
       "       8.62068966e-02, 1.00000000e-01, 4.00000000e-01, 2.00000000e-01,\n",
       "       2.00000000e-01, 2.00000000e-01, 4.00000000e-01, 1.48892434e-01,\n",
       "       6.78575089e-02, 8.78171337e-02, 1.63219937e-01, 8.40739510e-02,\n",
       "       2.63484742e-01, 0.00000000e+00, 5.93732912e-04, 1.11602161e-03,\n",
       "       1.61030596e-03, 0.00000000e+00, 3.78310691e-03])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Categorical to Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# #for country column\n",
    "# labelencoder_X_1 = LabelEncoder()\n",
    "# X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "# #for gender column\n",
    "# labelencoder_X_2 = LabelEncoder()\n",
    "# X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "# np.shape(X)\n",
    "# X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Baseline Model-Using Buildin Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model(using 1 connected layer and one 1 output layer)\n",
    "def create_baseline():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=23, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(23, input_dim=30, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, input_dim=23, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, input_dim=23, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='random_normal', activation='tanh'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-247-862ee254fac3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_baseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Results: %.2f%% (%.2f%%)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[0;32m    441\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    244\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    245\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 246\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    247\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    248\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid shape for y: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1156\u001b[0m                 _r=1):\n\u001b[0;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=50, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model-Using Sequential Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34343434, 1.        , 0.16666667, ..., 0.02333977, 0.12726919,\n",
       "        0.01267719],\n",
       "       [0.04040404, 0.        , 0.33333333, ..., 0.00111272, 0.00234451,\n",
       "        0.00151324],\n",
       "       [0.19191919, 1.        , 0.5       , ..., 0.01127214, 0.01172253,\n",
       "        0.00945777],\n",
       "       ...,\n",
       "       [0.13131313, 0.        , 0.16666667, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.01010101, 0.        , 0.33333333, ..., 0.00161031, 0.00137154,\n",
       "        0.00189155],\n",
       "       [0.04040404, 1.        , 0.33333333, ..., 0.00563607, 0.00820577,\n",
       "        0.00302649]])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34343434, 1.        , 0.16666667, ..., 0.02333977, 0.12726919,\n",
       "        0.01267719],\n",
       "       [0.04040404, 0.        , 0.33333333, ..., 0.00111272, 0.00234451,\n",
       "        0.00151324],\n",
       "       [0.19191919, 1.        , 0.5       , ..., 0.01127214, 0.01172253,\n",
       "        0.00945777],\n",
       "       ...,\n",
       "       [0.13131313, 0.        , 0.16666667, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.01010101, 0.        , 0.33333333, ..., 0.00161031, 0.00137154,\n",
       "        0.00189155],\n",
       "       [0.04040404, 1.        , 0.33333333, ..., 0.00563607, 0.00820577,\n",
       "        0.00302649]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000,)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# import keras\n",
    "# from keras import layers\n",
    "# from keras import models\n",
    "# from keras import utils\n",
    "# from keras.layers import Dense\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Flatten\n",
    "# from keras.layers import Dropout\n",
    "# from keras.layers import Activation\n",
    "# from keras.regularizers import l2\n",
    "# from keras.optimizers import SGD\n",
    "# from keras.optimizers import RMSprop\n",
    "# from keras import datasets\n",
    "\n",
    "# from keras.callbacks import LearningRateScheduler\n",
    "# from keras.callbacks import History\n",
    "\n",
    "# from keras import losses\n",
    "# from sklearn.utils import shuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.1)\n",
    "optimizer1 = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "optimizer2 = keras.optimizers.Adam(learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{loss:.2f}.h5'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4878 - accuracy: 0.7926\n",
      "Epoch 2/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4694 - accuracy: 0.8028\n",
      "Epoch 3/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4613 - accuracy: 0.8083\n",
      "Epoch 4/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4575 - accuracy: 0.8115\n",
      "Epoch 5/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4597 - accuracy: 0.8087\n",
      "Epoch 6/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4545 - accuracy: 0.8111\n",
      "Epoch 7/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4531 - accuracy: 0.8141\n",
      "Epoch 8/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4523 - accuracy: 0.8136\n",
      "Epoch 9/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4530 - accuracy: 0.8148\n",
      "Epoch 10/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4555 - accuracy: 0.8149\n",
      "Epoch 11/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4518 - accuracy: 0.8157\n",
      "Epoch 12/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4520 - accuracy: 0.8146\n",
      "Epoch 13/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4519 - accuracy: 0.8149\n",
      "Epoch 14/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4494 - accuracy: 0.8127\n",
      "Epoch 15/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4463 - accuracy: 0.8164\n",
      "Epoch 16/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4464 - accuracy: 0.8164\n",
      "Epoch 17/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4465 - accuracy: 0.8148\n",
      "Epoch 18/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4478 - accuracy: 0.8146\n",
      "Epoch 19/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4444 - accuracy: 0.8179\n",
      "Epoch 20/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4430 - accuracy: 0.8168\n",
      "Epoch 21/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4437 - accuracy: 0.8168\n",
      "Epoch 22/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4460 - accuracy: 0.8152\n",
      "Epoch 23/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4460 - accuracy: 0.8161\n",
      "Epoch 24/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4547 - accuracy: 0.8104\n",
      "Epoch 25/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4432 - accuracy: 0.8148\n",
      "Epoch 26/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4437 - accuracy: 0.8163\n",
      "Epoch 27/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4427 - accuracy: 0.8158\n",
      "Epoch 28/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4468 - accuracy: 0.8147\n",
      "Epoch 29/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4443 - accuracy: 0.8162\n",
      "Epoch 30/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4423 - accuracy: 0.8173\n",
      "Epoch 31/50\n",
      "4800/4800 [==============================] - 11s 2ms/step - loss: 0.4422 - accuracy: 0.8153\n",
      "Epoch 32/50\n",
      "4800/4800 [==============================] - 11s 2ms/step - loss: 0.4439 - accuracy: 0.8169\n",
      "Epoch 33/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4422 - accuracy: 0.8147\n",
      "Epoch 34/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4414 - accuracy: 0.8165\n",
      "Epoch 35/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4448 - accuracy: 0.8168\n",
      "Epoch 36/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4445 - accuracy: 0.8160\n",
      "Epoch 37/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4435 - accuracy: 0.8170\n",
      "Epoch 38/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4429 - accuracy: 0.8160\n",
      "Epoch 39/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4461 - accuracy: 0.8140\n",
      "Epoch 40/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4449 - accuracy: 0.8159\n",
      "Epoch 41/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4432 - accuracy: 0.8155\n",
      "Epoch 42/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4429 - accuracy: 0.8160\n",
      "Epoch 43/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4423 - accuracy: 0.8172\n",
      "Epoch 44/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4432 - accuracy: 0.8164\n",
      "Epoch 45/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4425 - accuracy: 0.8157\n",
      "Epoch 46/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4592 - accuracy: 0.8141\n",
      "Epoch 47/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4411 - accuracy: 0.8172\n",
      "Epoch 48/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4414 - accuracy: 0.8160\n",
      "Epoch 49/50\n",
      "4800/4800 [==============================] - 10s 2ms/step - loss: 0.4430 - accuracy: 0.8159\n",
      "Epoch 50/50\n",
      "4800/4800 [==============================] - 9s 2ms/step - loss: 0.4947 - accuracy: 0.8152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x279b71ea9d0>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initializing Neural Network\n",
    "Model = keras.Sequential()\n",
    "Model.add(Dense(100, input_dim = 23, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
    "# Adding the second hidden layer\n",
    "Model.add(Dense(200, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
    "# Adding the third hidden layer\n",
    "Model.add(Dense(300, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "# Adding the Fourth hidden layer\n",
    "Model.add(Dense(200, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
    "# Adding the output layer\n",
    "Model.add(Dense(1, kernel_initializer = 'random_uniform', activation = 'sigmoid'))\n",
    "# Compiling Neural Network\n",
    "Model.compile(optimizer = optimizer2, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#fitting the neural Network\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "Model.fit(X_train, y_train, batch_size = 5, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.8130\n",
      "Accuracy:  81.30000233650208\n",
      "loss: 44.25054490566254\n"
     ]
    }
   ],
   "source": [
    "score = Model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Accuracy: ', score[1]*100)\n",
    "print( 'loss:', score[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240000, array([[ 1.1616160e-37,  1.0587055e-37,  1.1367075e-37, ...,\n",
      "         1.1436810e-37,  1.1011645e-37,  1.0726497e-37],\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  1.0999606e-37, ...,\n",
      "         1.1396685e-37,  1.0972972e-37,  1.1254006e-37],\n",
      "       [ 1.1328309e-37,  1.1654273e-37,  1.1466868e-37, ...,\n",
      "         1.0644502e-37,  1.0698287e-37,  1.1246911e-37],\n",
      "       ...,\n",
      "       [ 1.1208853e-37,  1.0626201e-37,  1.1560830e-37, ...,\n",
      "         1.1269845e-37,  1.0597427e-37,  0.0000000e+00],\n",
      "       [ 1.0662006e-37,  1.1562454e-37,  1.0755542e-37, ...,\n",
      "         1.1484442e-37,  1.1501106e-37,  1.0864880e-37],\n",
      "       [ 1.0914205e-37,  1.1155625e-37,  1.1117529e-37, ...,\n",
      "        -1.1534162e-37,  1.1734016e-37,  0.0000000e+00]], dtype=float32), array([ 1.0664832e-37,  1.1536083e-37,  1.0586387e-37,  1.1732489e-37,\n",
      "        1.1066899e-37,  1.1107275e-37,  1.0865516e-37,  1.1530246e-37,\n",
      "        1.1618991e-37, -1.0732343e-02,  1.1519771e-37,  1.0590384e-37,\n",
      "        1.0823827e-37,  1.1453389e-37,  1.0878941e-37,  1.1220781e-37,\n",
      "        1.0734374e-37,  1.1417046e-37,  1.1626041e-37,  1.1679745e-37,\n",
      "        1.1629420e-37,  1.0805386e-37,  1.1344375e-37,  1.1695364e-37,\n",
      "        0.0000000e+00,  1.1472372e-37,  1.1229875e-37, -7.2584325e-03,\n",
      "        1.1362319e-37,  1.0681053e-37,  0.0000000e+00,  1.1280261e-37,\n",
      "        1.1477906e-37,  1.0993062e-37,  1.0877871e-37,  1.1511902e-37,\n",
      "        1.1540543e-37,  1.0638276e-37,  1.0759670e-37,  1.1675305e-37,\n",
      "        1.1235892e-37,  1.1730543e-37,  1.0709781e-37,  1.1325993e-37,\n",
      "        1.0921077e-37,  1.0647140e-37,  1.0725468e-37,  1.1630853e-37,\n",
      "        1.1498195e-37,  1.1476798e-37,  1.1394453e-37,  1.1661685e-37,\n",
      "        1.1721145e-37,  1.1213749e-37,  1.1687512e-37,  1.1067292e-37,\n",
      "        1.1352626e-37,  1.0914061e-37,  1.1080406e-37,  1.1122295e-37,\n",
      "        1.0778662e-37,  1.1505438e-37,  1.0816596e-37,  1.1106297e-37,\n",
      "        1.0879967e-37, -9.0609828e-04,  1.1468856e-37,  1.1205365e-37,\n",
      "        1.1556632e-37,  1.1423394e-37,  1.0606111e-37,  1.0832279e-37,\n",
      "       -7.3228693e-03,  1.0977860e-37,  1.1024292e-37,  1.1184376e-37,\n",
      "        1.1522684e-37,  1.1740517e-37,  1.1562364e-37,  1.0591550e-37,\n",
      "        1.1083766e-37,  1.1370688e-37,  1.1508696e-37,  1.0819478e-37,\n",
      "        1.1347523e-37,  1.1206787e-37,  1.1120365e-37,  1.1154755e-37,\n",
      "        1.1146381e-37,  1.1383992e-37,  1.0662951e-37,  1.0796574e-37,\n",
      "        1.0868794e-37,  1.1062209e-37,  1.0980818e-37,  1.1259406e-37,\n",
      "        1.0613207e-37,  1.1375945e-37,  1.0796917e-37,  1.1254006e-37],\n",
      "      dtype=float32), array([[-1.1462888e-37,  0.0000000e+00, -1.0752016e-37, ...,\n",
      "         0.0000000e+00,  0.0000000e+00, -1.1726350e-37],\n",
      "       [-1.1500826e-37,  1.1410010e-37, -1.0635029e-37, ...,\n",
      "         0.0000000e+00, -1.0787425e-37, -1.1232157e-37],\n",
      "       [-1.1217881e-37, -1.0933482e-37, -1.1558469e-37, ...,\n",
      "         0.0000000e+00,  1.1068135e-37,  1.1184042e-37],\n",
      "       ...,\n",
      "       [ 1.0860527e-37,  1.0665194e-37,  1.1515606e-37, ...,\n",
      "         0.0000000e+00,  1.1510826e-37,  1.1014516e-37],\n",
      "       [ 1.1389700e-37,  1.0813979e-37,  1.1057869e-37, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  1.0870737e-37],\n",
      "       [ 0.0000000e+00,  0.0000000e+00, -1.0887802e-37, ...,\n",
      "         0.0000000e+00, -1.1724175e-37, -1.0971177e-37]], dtype=float32), array([ 1.0752859e-37,  1.1156853e-37,  1.1229025e-37,  1.0665957e-37,\n",
      "        1.1153104e-37,  1.1342101e-37,  1.1001759e-37,  1.0746762e-37,\n",
      "        1.0730631e-37,  1.1166622e-37,  1.1060644e-37,  1.1002740e-37,\n",
      "        1.1157420e-37,  1.0586254e-37,  1.1385244e-37,  1.0731843e-37,\n",
      "        1.1112956e-37,  1.0689048e-37,  1.1353911e-37,  1.1425896e-37,\n",
      "        1.1002184e-37,  6.9204513e-03,  1.0700382e-37,  1.1402107e-37,\n",
      "        1.1530766e-37,  1.0653752e-37,  1.1165177e-37,  3.0158986e-03,\n",
      "        1.0702434e-37,  1.0802510e-37,  1.0632952e-37,  1.1052570e-37,\n",
      "        1.0852022e-37,  1.1126969e-37,  1.1613720e-37,  1.1735778e-37,\n",
      "        1.1196129e-37,  1.1405001e-37,  1.1309077e-37,  1.0965773e-37,\n",
      "        1.1020480e-37,  1.1190605e-37,  1.0581940e-37,  1.1255559e-37,\n",
      "        1.1496587e-37,  1.0718382e-37,  1.1263319e-37,  1.1250013e-37,\n",
      "        1.0733244e-37,  1.1640452e-37,  1.0825987e-37,  1.1232134e-37,\n",
      "        1.1626305e-37,  1.1391692e-37,  1.1368995e-37,  1.1329961e-37,\n",
      "        1.1724091e-37,  1.1267901e-37,  1.1696806e-37,  3.4743489e-04,\n",
      "        1.0702545e-37,  1.0766932e-37,  1.0598742e-37,  1.0859220e-37,\n",
      "        1.0757266e-37,  1.1749884e-37,  1.1077179e-37,  1.0856599e-37,\n",
      "        1.0765808e-37,  1.1692373e-37,  1.1614026e-37,  1.1191396e-37,\n",
      "        1.0955280e-37,  1.0620990e-37,  1.1237396e-37,  1.1590858e-37,\n",
      "        1.0901878e-37,  1.1428905e-37,  1.0614096e-37,  1.1443905e-37,\n",
      "        1.1225495e-37,  1.1308373e-37,  1.0773620e-37,  1.1346204e-37,\n",
      "        1.1700732e-37,  1.1281529e-37,  1.1753829e-37,  1.1489372e-37,\n",
      "        1.0753609e-37,  1.0712103e-37,  1.0998591e-37,  1.1523033e-37,\n",
      "        1.1284801e-37,  1.1071719e-37,  1.1445752e-37,  1.1111491e-37,\n",
      "        1.1228284e-37,  1.0699188e-37, -1.0721720e-37,  1.1565805e-37,\n",
      "        1.1040140e-37,  1.0927015e-37,  1.1543324e-37,  1.1679152e-37,\n",
      "        1.1228640e-37,  1.1485805e-37,  1.1346603e-37,  1.1273747e-37,\n",
      "        1.0599437e-37,  1.1632940e-37,  1.1002092e-37,  1.1665916e-37,\n",
      "        1.0602919e-37,  1.1058808e-37,  1.0982636e-37,  1.0714883e-37,\n",
      "        1.1242621e-37,  1.1046022e-37,  1.0801415e-37,  1.0981460e-37,\n",
      "        1.0795356e-37,  1.0829506e-37,  1.1316981e-37,  1.1677846e-37,\n",
      "        1.1293521e-37,  1.0604776e-37,  1.1585787e-37,  1.1642078e-37,\n",
      "        1.1465923e-37,  1.1475676e-37,  1.1148562e-37,  1.1578129e-37,\n",
      "        1.1511845e-37,  1.1189171e-37,  1.0900206e-37,  1.1444346e-37,\n",
      "        1.1638766e-37,  2.7394798e-04,  1.1139574e-37,  1.0948457e-37,\n",
      "        1.1646521e-37,  1.0697981e-37,  1.1370981e-37,  1.0905593e-37,\n",
      "        1.0903993e-37,  1.1312385e-37,  1.1617444e-37,  1.1647911e-37,\n",
      "        1.1289976e-37,  1.1752173e-37,  1.1119076e-37,  1.1160636e-37,\n",
      "        1.1198175e-37,  1.1281986e-37,  1.1488142e-37,  1.1316521e-37,\n",
      "        1.0608305e-37,  1.1177846e-37,  1.1296008e-37,  1.1674401e-37,\n",
      "        1.1243752e-37,  1.0723343e-37,  1.1420569e-37,  1.1418368e-37,\n",
      "        1.1165561e-37,  1.1601546e-37,  1.1083951e-37,  1.1042985e-37,\n",
      "        1.1604105e-37,  1.1696119e-37,  1.0658310e-37,  1.1189653e-37,\n",
      "        1.1236150e-37,  1.1659572e-37,  1.1061816e-37,  1.1213742e-37,\n",
      "        1.0714753e-37,  1.1177492e-37,  1.1534755e-37,  1.1691695e-37,\n",
      "        1.0771884e-37,  1.1508843e-37,  1.1073722e-37,  1.0977670e-37,\n",
      "        1.0679504e-37,  1.0589453e-37,  1.1597217e-37,  1.0757776e-37,\n",
      "        1.0641954e-37,  1.0991572e-37,  1.0682168e-37,  1.1472226e-37,\n",
      "        1.0843380e-37,  1.1323326e-37,  1.1184283e-37,  1.1657617e-37,\n",
      "        1.1272176e-37,  1.0965475e-37,  1.0771069e-37,  1.0918989e-37],\n",
      "      dtype=float32), array([[-1.0741205e-37,  1.1351203e-37,  1.1297621e-37, ...,\n",
      "         1.0814801e-37, -1.1360479e-37,  1.0854046e-37],\n",
      "       [-1.0612715e-37,  1.0601321e-37,  1.1538214e-37, ...,\n",
      "        -1.0916496e-37,  1.0964304e-37,  0.0000000e+00],\n",
      "       [-1.0670518e-37,  1.0678301e-37,  1.1094110e-37, ...,\n",
      "         1.1524246e-37,  1.1737145e-37,  1.0671905e-37],\n",
      "       ...,\n",
      "       [-1.0946719e-37,  1.1037664e-37,  1.1222267e-37, ...,\n",
      "         1.1389866e-37,  1.0800098e-37,  0.0000000e+00],\n",
      "       [-1.1192662e-37,  1.1638962e-37,  1.1716853e-37, ...,\n",
      "         1.0851684e-37, -1.1109489e-37,  1.1454335e-37],\n",
      "       [-1.0968255e-37, -1.1727810e-37,  1.0718940e-37, ...,\n",
      "         1.0703413e-37, -1.1507497e-37, -1.1649274e-37]], dtype=float32), array([ 1.0951218e-37,  1.1724844e-37,  1.0729354e-37,  1.1015547e-37,\n",
      "        1.1464324e-37,  1.0753609e-37,  1.1121244e-37,  1.1212550e-37,\n",
      "        1.1475113e-37,  1.1247617e-37,  1.0917137e-37,  1.1296472e-37,\n",
      "        1.0618886e-37,  1.0833688e-37,  1.1055742e-37,  1.0708491e-37,\n",
      "       -1.1541489e-37,  1.1724995e-37,  1.1718147e-37,  1.0758216e-37,\n",
      "        1.1663753e-37, -1.1561102e-37,  1.0706491e-37,  1.1421209e-37,\n",
      "        1.0966211e-37,  1.1332784e-37,  1.0826892e-37,  1.0892217e-37,\n",
      "        1.1720608e-37,  1.1167336e-37,  1.0869172e-37,  1.1107832e-37,\n",
      "        1.1700965e-37,  1.1335623e-37,  1.1720637e-37,  1.0646821e-37,\n",
      "        1.1318037e-37,  1.1422337e-37,  1.1743120e-37,  1.0722373e-37,\n",
      "        1.0990273e-37,  1.1372422e-37,  1.1309267e-37,  1.0806677e-37,\n",
      "        1.0997908e-37,  1.0957055e-37,  1.1480185e-37,  1.0740087e-37,\n",
      "        1.0701863e-37,  1.1677231e-37,  1.0741941e-37,  1.1584853e-37,\n",
      "        1.0841084e-37,  1.1380999e-37, -1.0886425e-37, -1.1708447e-37,\n",
      "        1.0620959e-37,  1.1056823e-37,  1.1556220e-37,  1.1618255e-37,\n",
      "       -1.1302685e-37,  1.0618661e-37,  1.0792674e-37,  1.1563645e-37,\n",
      "        1.1664105e-37,  1.1100926e-37,  1.1617395e-37,  1.1396939e-37,\n",
      "        1.1324590e-37,  1.0964884e-37,  1.1635109e-37,  1.1202005e-37,\n",
      "        1.1344579e-37,  1.1273022e-37,  1.1515151e-37,  1.1730967e-37,\n",
      "        1.1677270e-37,  1.0747652e-37,  1.0962224e-37, -1.1336973e-37,\n",
      "        1.1259284e-37,  1.1659572e-37,  1.1448416e-37,  1.1004805e-37,\n",
      "        1.1130265e-37,  1.0692031e-37,  1.1340778e-37,  1.0760645e-37,\n",
      "        1.0742438e-37,  1.0984480e-37,  1.1666612e-37,  1.0892671e-37,\n",
      "        1.1346719e-37, -1.1516876e-37,  1.0698692e-37,  1.1573478e-37,\n",
      "        1.1137987e-37,  1.1211417e-37,  1.1347912e-37,  1.0959189e-37,\n",
      "        1.1155927e-37,  1.1520707e-37,  1.1045825e-37,  1.1011740e-37,\n",
      "        1.1751894e-37,  1.1005191e-37,  1.0636629e-37,  1.1409108e-37,\n",
      "        1.1575035e-37,  1.0893316e-37,  1.1719642e-37,  1.0936212e-37,\n",
      "        1.1164239e-37,  1.0693315e-37,  1.0601298e-37,  1.0842727e-37,\n",
      "        1.1319615e-37,  1.1232535e-37,  1.1350579e-37,  1.1627197e-37,\n",
      "        1.0612789e-37,  1.1515911e-37,  1.1092278e-37,  1.0673647e-37,\n",
      "        1.1057387e-37,  1.1693863e-37,  1.0756527e-37,  1.1136726e-37,\n",
      "        1.1107943e-37,  1.1698843e-37,  1.0881696e-37,  1.1395175e-37,\n",
      "        1.1481271e-37,  1.0838541e-37,  1.1593006e-37,  1.1636220e-37,\n",
      "        1.0999089e-37,  1.1247018e-37,  1.1316487e-37,  1.0760746e-37,\n",
      "        1.1525166e-37,  1.1002457e-37,  1.1516398e-37,  1.1392136e-37,\n",
      "        1.0784077e-37,  1.1109313e-37,  1.1278630e-37,  1.1088727e-37,\n",
      "        1.1388445e-37,  1.1206735e-37, -1.1350293e-37,  1.1682177e-37,\n",
      "        1.0798609e-37,  1.1287017e-37, -1.0797430e-37,  1.0596015e-37,\n",
      "        1.9600611e-02,  1.1096676e-37,  1.1447458e-37,  1.1248032e-37,\n",
      "        1.1276813e-37,  1.0707317e-37,  1.0912365e-37,  1.1341037e-37,\n",
      "        1.1621461e-37,  1.0947731e-37,  1.1295582e-37,  1.1429301e-37,\n",
      "        1.0724916e-37,  1.0728785e-37,  1.1533292e-37,  1.0902279e-37,\n",
      "        1.0661451e-37,  1.1248968e-37,  1.1191364e-37,  1.1111890e-37,\n",
      "        1.1668723e-37,  1.0624589e-37,  1.1394244e-37,  1.0817625e-37,\n",
      "        1.0603847e-37,  1.0890013e-37,  1.1095081e-37,  1.0793986e-37,\n",
      "        1.1340882e-37,  1.0763710e-37,  1.0902927e-37,  1.1219808e-37,\n",
      "        1.1172345e-37,  1.1460180e-37,  1.1084136e-37,  1.0627737e-37,\n",
      "        1.1408937e-37,  1.1487822e-37,  1.0934535e-37,  1.0607745e-37,\n",
      "        1.0754933e-37,  1.0784141e-37,  1.1101233e-37,  1.0854907e-37,\n",
      "        1.0765211e-37,  1.1117985e-37,  1.0947821e-37,  1.1427616e-37,\n",
      "        1.1557590e-37,  1.1433091e-37,  1.1676026e-37,  1.1452878e-37,\n",
      "        1.0647016e-37,  1.1139995e-37,  1.1394784e-37,  1.0940285e-37,\n",
      "        1.1434375e-37,  1.0792823e-37,  1.1589245e-37,  1.1286075e-37,\n",
      "        1.1439742e-37,  1.0910665e-37,  1.1038326e-37,  1.1428234e-37,\n",
      "        1.0751637e-37, -1.1438026e-37,  1.0933634e-37,  1.0944277e-37,\n",
      "        1.1465176e-37,  1.1012959e-37,  1.0592131e-37,  1.1105701e-37,\n",
      "        1.1606292e-37,  1.1009439e-37,  1.1126453e-37, -1.1192181e-37,\n",
      "        1.1133284e-37,  1.0750930e-37,  1.0854674e-37,  1.1346603e-37,\n",
      "        1.0816006e-37,  1.1155967e-37,  1.1369730e-37,  1.0948569e-37,\n",
      "        1.1473410e-37,  1.1261062e-37,  1.0847454e-37,  1.1724211e-37,\n",
      "        1.0882569e-37,  1.0600787e-37,  1.1371494e-37,  1.1669461e-37,\n",
      "        1.0855080e-37, -1.1101060e-37,  1.1589511e-37, -1.1132832e-37,\n",
      "        1.1104983e-37,  1.1016902e-37,  1.0766138e-37,  1.0761060e-37,\n",
      "        1.1153887e-37,  1.0997662e-37,  1.0659203e-37,  1.0684679e-37,\n",
      "        1.1210752e-37, -1.1734060e-37,  1.0619479e-37,  1.1435838e-37,\n",
      "        1.1340148e-37, -1.0785570e-37,  1.1501352e-37,  1.0973706e-37,\n",
      "        1.0938674e-37,  1.1369560e-37,  1.1110651e-37,  1.1255464e-37,\n",
      "        1.0923164e-37,  1.1206684e-37,  1.0744753e-37,  1.1023625e-37,\n",
      "        1.1051572e-37,  1.1056376e-37,  1.0725554e-37,  1.1703313e-37,\n",
      "        1.1638137e-37,  1.1682177e-37,  1.1526378e-37,  1.1077586e-37,\n",
      "        1.0767730e-37,  1.1481354e-37,  1.1629873e-37,  1.0696174e-37,\n",
      "        1.1194507e-37,  1.0610495e-37,  1.0623737e-37,  1.0876172e-37,\n",
      "        1.1719482e-37,  1.1740026e-37,  1.1268854e-37,  1.0883176e-37,\n",
      "        1.1321958e-37,  1.0792231e-37,  1.0868139e-37,  1.0588389e-37],\n",
      "      dtype=float32), array([[-1.1254415e-37,  1.0703513e-37,  1.1388895e-37, ...,\n",
      "         1.1306420e-37,  1.0938232e-37,  1.0693593e-37],\n",
      "       [ 1.1519340e-37,  1.1502171e-37,  1.0752364e-37, ...,\n",
      "         1.1115824e-37, -1.1022211e-37,  1.0782718e-37],\n",
      "       [ 1.1684558e-37,  1.1397161e-37,  0.0000000e+00, ...,\n",
      "         0.0000000e+00,  1.1709858e-37,  1.0895511e-37],\n",
      "       ...,\n",
      "       [ 0.0000000e+00,  1.1324238e-37, -1.1539464e-37, ...,\n",
      "         1.1028063e-37,  1.1743430e-37,  1.0978464e-37],\n",
      "       [ 1.1733130e-37,  1.0702601e-37, -1.1483275e-37, ...,\n",
      "         1.0989508e-37,  1.1545944e-37, -1.1741391e-37],\n",
      "       [ 0.0000000e+00,  1.0754104e-37,  0.0000000e+00, ...,\n",
      "         0.0000000e+00, -1.0787308e-37,  1.1115112e-37]], dtype=float32), array([ 1.0742289e-37,  1.1325347e-37, -1.1240233e-37,  1.0737217e-37,\n",
      "        1.1728849e-37,  1.1011463e-37,  1.1438701e-37,  1.1298436e-37,\n",
      "       -1.0965060e-37, -1.1742719e-37,  1.0759338e-37,  1.1666014e-37,\n",
      "        1.0585953e-37,  1.1021405e-37, -1.1692098e-37,  1.1580742e-37,\n",
      "        1.0914133e-37,  1.1432777e-37,  1.1576877e-37,  1.1302509e-37,\n",
      "        1.0695721e-37,  1.1353748e-37,  1.1735112e-37, -1.0662917e-37,\n",
      "        1.1606176e-37,  1.1123049e-37,  1.1663718e-37, -1.1540091e-37,\n",
      "        1.1347289e-37, -1.1731966e-37,  1.0996213e-37,  1.0758012e-37,\n",
      "       -1.1185809e-37, -1.0735191e-37,  1.1313767e-37,  1.1623909e-37,\n",
      "        1.1438845e-37,  1.1744232e-37,  1.1295127e-37,  1.0686641e-37,\n",
      "        1.0971834e-37, -1.0877689e-37,  1.0732415e-37, -1.1680079e-37,\n",
      "       -1.0624538e-37,  1.1620476e-37,  1.1382419e-37, -1.1377520e-37,\n",
      "       -1.0906814e-37,  1.1331052e-37,  1.1690681e-37,  1.1735881e-37,\n",
      "        1.0614648e-37,  1.1587403e-37, -1.1040544e-37,  1.0699205e-37,\n",
      "       -1.1346153e-37,  1.0923040e-37,  1.0828112e-37,  1.0711045e-37,\n",
      "        1.1250514e-37,  1.0848763e-37, -1.0866126e-37,  1.0855828e-37,\n",
      "        1.0911959e-37,  1.0642530e-37,  1.1721250e-37,  1.0733880e-37,\n",
      "       -1.0962719e-37,  1.0915787e-37, -1.1365547e-37,  1.1646213e-37,\n",
      "       -1.1386440e-37,  1.0913644e-37, -1.1641108e-37,  1.0728260e-37,\n",
      "        1.0790749e-37,  1.1461755e-37,  1.1441387e-37,  1.0784464e-37,\n",
      "        1.0721572e-37,  1.1451666e-37,  1.0772333e-37,  1.1596929e-37,\n",
      "       -1.1070907e-37,  1.1340286e-37, -1.1318481e-37,  1.1026679e-37,\n",
      "        1.1358453e-37,  1.1226434e-37,  1.1590532e-37,  1.1534793e-37,\n",
      "        1.1152183e-37, -1.1632090e-37,  1.1745912e-37,  1.1348874e-37,\n",
      "        1.1091432e-37, -1.0951280e-37,  1.0677206e-37,  1.1473196e-37,\n",
      "        1.0742838e-37,  1.1301371e-37,  1.1222238e-37,  1.1249199e-37,\n",
      "        1.1184350e-37, -1.1467131e-37,  1.1699958e-37,  1.1198260e-37,\n",
      "        1.1608565e-37, -1.0824500e-37,  1.0842675e-37,  1.0930079e-37,\n",
      "       -1.0856034e-37, -1.1494647e-37,  1.1643131e-37,  1.1210487e-37,\n",
      "       -1.1738495e-37,  1.1431820e-37,  1.0659951e-37,  1.0861653e-37,\n",
      "        1.1581299e-37,  1.1267125e-37,  1.1418669e-37, -1.1619117e-37,\n",
      "        1.0690797e-37,  1.0959964e-37,  1.0896019e-37,  1.0685886e-37,\n",
      "       -1.1348892e-37, -1.0693542e-37,  1.1509364e-37,  1.0672507e-37,\n",
      "        1.0838972e-37,  1.0656442e-37, -1.1103981e-37,  1.1227976e-37,\n",
      "        1.1719784e-37,  1.1526206e-37,  1.1462283e-37,  1.1106215e-37,\n",
      "       -1.0643017e-37, -2.6425993e-02,  1.1284214e-37,  1.1030785e-37,\n",
      "       -1.1322849e-37,  1.1031932e-37,  1.1442094e-37,  1.1053281e-37,\n",
      "        1.0615297e-37, -1.0786458e-37,  1.1675943e-37,  1.1118090e-37,\n",
      "        1.1351127e-37,  1.1626706e-37,  1.0959693e-37,  1.1364917e-37,\n",
      "       -1.1307756e-37,  1.0782783e-37,  1.1163291e-37,  1.1014833e-37,\n",
      "        1.0993136e-37,  1.1408557e-37,  1.1085867e-37, -1.0629726e-37,\n",
      "        1.0582653e-37, -1.0714382e-37, -1.0844096e-37,  1.1070845e-37,\n",
      "       -1.0881687e-37,  1.1614500e-37,  1.1740725e-37,  1.1603671e-37,\n",
      "        2.4864264e-03, -1.1247577e-37,  1.1425132e-37,  1.0819030e-37,\n",
      "        1.1163226e-37,  1.0701700e-37,  1.1388775e-37,  1.0797312e-37,\n",
      "       -1.1051459e-37,  1.0687081e-37, -1.0985054e-37,  1.1055048e-37,\n",
      "        1.1306899e-37, -1.0729357e-37, -1.0998760e-37,  1.1653322e-37,\n",
      "        1.0986952e-37,  1.0605741e-37,  1.0885345e-37,  1.0879190e-37,\n",
      "        1.1214028e-37,  1.0789222e-37, -1.1023361e-37,  1.1676035e-37,\n",
      "        1.1723239e-37,  1.1679850e-37,  1.0652443e-37,  1.1722705e-37],\n",
      "      dtype=float32), array([[ 1.09249376e-37],\n",
      "       [ 1.15403957e-37],\n",
      "       [ 1.08116690e-37],\n",
      "       [ 1.11535847e-37],\n",
      "       [ 1.13563806e-37],\n",
      "       [ 1.11913637e-37],\n",
      "       [ 1.16460211e-37],\n",
      "       [-1.15849245e-37],\n",
      "       [ 1.06281863e-37],\n",
      "       [ 1.12878201e-37],\n",
      "       [ 1.15007435e-37],\n",
      "       [-1.15417780e-37],\n",
      "       [ 1.13624746e-37],\n",
      "       [ 1.06015112e-37],\n",
      "       [ 1.10354631e-37],\n",
      "       [ 1.06952771e-37],\n",
      "       [ 1.11038778e-37],\n",
      "       [ 1.14753105e-37],\n",
      "       [ 1.07786443e-37],\n",
      "       [ 1.17447320e-37],\n",
      "       [ 1.06634441e-37],\n",
      "       [-1.13535376e-37],\n",
      "       [ 1.16898638e-37],\n",
      "       [ 1.15537731e-37],\n",
      "       [ 1.10183515e-37],\n",
      "       [ 1.10486711e-37],\n",
      "       [ 1.08270081e-37],\n",
      "       [ 1.08634722e-37],\n",
      "       [ 1.08231921e-37],\n",
      "       [ 1.09396681e-37],\n",
      "       [ 1.08142541e-37],\n",
      "       [ 1.13114135e-37],\n",
      "       [ 1.06709495e-37],\n",
      "       [ 1.07831565e-37],\n",
      "       [ 1.05891865e-37],\n",
      "       [ 1.07596830e-37],\n",
      "       [ 1.08361390e-37],\n",
      "       [ 1.11598367e-37],\n",
      "       [ 1.06431881e-37],\n",
      "       [ 1.06378642e-37],\n",
      "       [ 1.06694977e-37],\n",
      "       [ 1.07712152e-37],\n",
      "       [ 1.10929432e-37],\n",
      "       [ 1.07079247e-37],\n",
      "       [ 1.08402846e-37],\n",
      "       [ 1.09280530e-37],\n",
      "       [ 1.08002646e-37],\n",
      "       [ 1.09951718e-37],\n",
      "       [ 1.16646416e-37],\n",
      "       [ 1.10646437e-37],\n",
      "       [ 1.13457677e-37],\n",
      "       [ 1.07087139e-37],\n",
      "       [ 1.16373510e-37],\n",
      "       [-1.14241777e-37],\n",
      "       [ 1.12084707e-37],\n",
      "       [-1.16153237e-37],\n",
      "       [ 1.11105357e-37],\n",
      "       [ 1.11442240e-37],\n",
      "       [ 1.17399474e-37],\n",
      "       [ 1.12207741e-37],\n",
      "       [ 1.13694967e-37],\n",
      "       [ 1.12694149e-37],\n",
      "       [ 1.16419036e-37],\n",
      "       [ 1.07499322e-37],\n",
      "       [ 1.10209187e-37],\n",
      "       [ 1.16151489e-37],\n",
      "       [ 1.06528906e-37],\n",
      "       [ 1.13818024e-37],\n",
      "       [ 1.06614173e-37],\n",
      "       [ 1.14527283e-37],\n",
      "       [ 1.12940587e-37],\n",
      "       [ 1.07288108e-37],\n",
      "       [ 1.09727925e-37],\n",
      "       [-1.10802463e-37],\n",
      "       [ 1.07066265e-37],\n",
      "       [-1.15757578e-37],\n",
      "       [ 1.10557953e-37],\n",
      "       [ 1.06090199e-37],\n",
      "       [-1.16458642e-37],\n",
      "       [-1.12729181e-37],\n",
      "       [ 1.05941493e-37],\n",
      "       [ 1.08963466e-37],\n",
      "       [ 1.16617448e-37],\n",
      "       [ 1.13070145e-37],\n",
      "       [ 1.15425896e-37],\n",
      "       [ 1.16084944e-37],\n",
      "       [ 1.09664463e-37],\n",
      "       [-1.05829737e-37],\n",
      "       [ 1.13999060e-37],\n",
      "       [ 1.07332882e-37],\n",
      "       [ 1.15356638e-37],\n",
      "       [-1.16969948e-37],\n",
      "       [ 1.11969364e-37],\n",
      "       [ 1.08021245e-37],\n",
      "       [ 1.07969172e-37],\n",
      "       [ 1.14606170e-37],\n",
      "       [-1.07750200e-37],\n",
      "       [ 1.09789369e-37],\n",
      "       [ 1.15594680e-37],\n",
      "       [ 1.16144774e-37],\n",
      "       [ 1.14686661e-37],\n",
      "       [ 1.13927796e-37],\n",
      "       [-1.09274017e-37],\n",
      "       [ 1.16260980e-37],\n",
      "       [ 1.08372197e-37],\n",
      "       [ 1.06442833e-37],\n",
      "       [ 1.06106432e-37],\n",
      "       [ 1.11671638e-37],\n",
      "       [ 1.12633187e-37],\n",
      "       [ 1.12280329e-37],\n",
      "       [ 1.09517955e-37],\n",
      "       [ 1.14278233e-37],\n",
      "       [ 1.14016885e-37],\n",
      "       [ 1.07774851e-37],\n",
      "       [-1.15483327e-37],\n",
      "       [-1.08708890e-37],\n",
      "       [ 1.06488033e-37],\n",
      "       [ 1.13963602e-37],\n",
      "       [ 1.06613422e-37],\n",
      "       [-1.14936025e-37],\n",
      "       [ 1.07144155e-37],\n",
      "       [-1.10985663e-37],\n",
      "       [ 1.10099695e-37],\n",
      "       [ 1.14450727e-37],\n",
      "       [-1.09342445e-37],\n",
      "       [ 1.15540892e-37],\n",
      "       [ 1.17505300e-37],\n",
      "       [ 1.07918098e-37],\n",
      "       [ 1.09477900e-37],\n",
      "       [ 1.09333970e-37],\n",
      "       [ 1.17145491e-37],\n",
      "       [ 1.15628950e-37],\n",
      "       [ 1.11955855e-37],\n",
      "       [ 1.11376379e-37],\n",
      "       [ 1.09015561e-37],\n",
      "       [ 1.08593938e-37],\n",
      "       [ 1.12320742e-37],\n",
      "       [ 1.12708375e-37],\n",
      "       [ 1.07332041e-37],\n",
      "       [-1.11930912e-37],\n",
      "       [ 1.11334082e-37],\n",
      "       [ 1.95659678e-02],\n",
      "       [ 1.16304678e-37],\n",
      "       [ 1.11775996e-37],\n",
      "       [ 1.16517564e-37],\n",
      "       [ 1.14428463e-37],\n",
      "       [ 1.11585610e-37],\n",
      "       [-1.05957681e-37],\n",
      "       [ 1.14674778e-37],\n",
      "       [ 1.08343711e-37],\n",
      "       [ 1.10615126e-37],\n",
      "       [ 1.06182147e-37],\n",
      "       [ 1.14366055e-37],\n",
      "       [ 1.10062936e-37],\n",
      "       [ 1.16575376e-37],\n",
      "       [ 1.12375146e-37],\n",
      "       [ 1.06826845e-37],\n",
      "       [ 1.07568143e-37],\n",
      "       [ 1.11781343e-37],\n",
      "       [ 1.10264230e-37],\n",
      "       [ 1.09351974e-37],\n",
      "       [ 1.12391177e-37],\n",
      "       [ 1.06001514e-37],\n",
      "       [ 1.06473606e-37],\n",
      "       [ 1.08717802e-37],\n",
      "       [ 1.10894142e-37],\n",
      "       [ 1.10821723e-37],\n",
      "       [-1.09192887e-37],\n",
      "       [ 1.15292863e-37],\n",
      "       [ 1.13873728e-37],\n",
      "       [ 1.17319230e-37],\n",
      "       [-1.14341123e-37],\n",
      "       [ 1.16905585e-01],\n",
      "       [ 1.12088530e-37],\n",
      "       [-1.11188370e-37],\n",
      "       [ 1.07776735e-37],\n",
      "       [ 1.11170063e-37],\n",
      "       [ 1.09892763e-37],\n",
      "       [ 1.11463977e-37],\n",
      "       [ 1.07260183e-37],\n",
      "       [ 1.11476824e-37],\n",
      "       [ 1.17279534e-37],\n",
      "       [ 1.13583760e-37],\n",
      "       [ 1.12288456e-37],\n",
      "       [ 1.11896160e-37],\n",
      "       [ 1.15543975e-37],\n",
      "       [ 1.09617480e-37],\n",
      "       [ 1.13710819e-37],\n",
      "       [ 1.14976629e-37],\n",
      "       [ 1.15006504e-37],\n",
      "       [ 1.07316369e-37],\n",
      "       [ 1.10995484e-37],\n",
      "       [ 1.12331089e-37],\n",
      "       [ 1.11160108e-37],\n",
      "       [ 1.16647907e-37],\n",
      "       [ 1.16806108e-37],\n",
      "       [ 1.15021504e-37],\n",
      "       [ 1.14080302e-37],\n",
      "       [ 1.11863661e-37],\n",
      "       [ 1.09114437e-37]], dtype=float32), array([0.03106644], dtype=float32), array([[1.17491966e-35, 1.17493451e-35, 1.17464954e-35, ...,\n",
      "        1.17446421e-35, 1.17494520e-35, 1.17516927e-35],\n",
      "       [0.00000000e+00, 0.00000000e+00, 1.17444140e-35, ...,\n",
      "        1.17510369e-35, 1.17449743e-35, 1.17461079e-35],\n",
      "       [1.17488680e-35, 1.17477846e-35, 1.17486614e-35, ...,\n",
      "        1.17531599e-35, 1.17539276e-35, 1.17487956e-35],\n",
      "       ...,\n",
      "       [1.17489168e-35, 1.17531599e-35, 1.17503668e-35, ...,\n",
      "        1.17476132e-35, 1.17539276e-35, 0.00000000e+00],\n",
      "       [1.17453783e-35, 1.17496687e-35, 1.17511460e-35, ...,\n",
      "        1.17461079e-35, 1.17453740e-35, 1.17474467e-35],\n",
      "       [1.17455117e-35, 1.17477638e-35, 1.17438802e-35, ...,\n",
      "        1.17526541e-35, 1.17505713e-35, 0.00000000e+00]], dtype=float32), array([1.17505713e-35, 1.17469854e-35, 1.17509601e-35, 1.17470270e-35,\n",
      "       1.17521841e-35, 1.17528047e-35, 1.17516927e-35, 1.17504751e-35,\n",
      "       1.17464437e-35, 2.01968267e-03, 1.17459214e-35, 1.17435150e-35,\n",
      "       1.17500131e-35, 1.17492691e-35, 1.17494520e-35, 1.17476907e-35,\n",
      "       1.17442382e-35, 1.17459214e-35, 1.17477638e-35, 1.17509601e-35,\n",
      "       1.17460276e-35, 1.17466683e-35, 1.17547835e-35, 1.17509601e-35,\n",
      "       0.00000000e+00, 1.17530336e-35, 1.17510685e-35, 1.93232242e-02,\n",
      "       1.17544915e-35, 1.17550318e-35, 0.00000000e+00, 1.17483392e-35,\n",
      "       1.17510685e-35, 1.17505713e-35, 1.17548890e-35, 1.17537109e-35,\n",
      "       8.75453185e-03, 1.17514208e-35, 1.17448983e-35, 1.17494520e-35,\n",
      "       1.17477638e-35, 1.17464853e-35, 1.17477653e-35, 1.17533830e-35,\n",
      "       1.17458862e-35, 1.17528047e-35, 1.17537109e-35, 1.17468720e-35,\n",
      "       1.17538874e-35, 1.17505713e-35, 1.17492691e-35, 1.17498538e-35,\n",
      "       1.17483392e-35, 1.17483701e-35, 1.17457592e-35, 1.17550318e-35,\n",
      "       1.17455354e-35, 1.17480092e-35, 1.17500102e-35, 1.17541600e-35,\n",
      "       1.17511460e-35, 1.17539276e-35, 1.17522494e-35, 1.17522494e-35,\n",
      "       1.17448732e-35, 3.20195756e-03, 1.17470270e-35, 1.17477638e-35,\n",
      "       1.17477638e-35, 1.17463095e-35, 1.17437841e-35, 1.17455103e-35,\n",
      "       6.08689990e-03, 1.17542131e-35, 1.17550332e-35, 1.17480092e-35,\n",
      "       1.17522494e-35, 1.17436520e-35, 1.17516927e-35, 1.17505713e-35,\n",
      "       1.17502534e-35, 1.17528047e-35, 1.17539276e-35, 1.17476132e-35,\n",
      "       1.17494520e-35, 1.17449743e-35, 1.17522494e-35, 1.17500102e-35,\n",
      "       1.17480092e-35, 1.17494563e-35, 1.17447132e-35, 1.17487188e-35,\n",
      "       1.17481269e-35, 1.17516927e-35, 1.17505713e-35, 1.17468720e-35,\n",
      "       1.17526541e-35, 1.17449743e-35, 1.17482352e-35, 1.17461079e-35],\n",
      "      dtype=float32), array([[1.17449743e-35, 0.00000000e+00, 1.17435150e-35, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 1.17528047e-35],\n",
      "       [1.17511460e-35, 1.17500346e-35, 1.17526555e-35, ...,\n",
      "        0.00000000e+00, 1.17465599e-35, 1.17507801e-35],\n",
      "       [1.17491371e-35, 1.17550691e-35, 1.17498581e-35, ...,\n",
      "        0.00000000e+00, 1.17539276e-35, 1.17464853e-35],\n",
      "       ...,\n",
      "       [1.17454837e-35, 1.17550318e-35, 1.17522494e-35, ...,\n",
      "        0.00000000e+00, 1.17447003e-35, 1.17466640e-35],\n",
      "       [1.17466015e-35, 1.17498581e-35, 1.17455103e-35, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 1.17492691e-35],\n",
      "       [0.00000000e+00, 0.00000000e+00, 1.17519990e-35, ...,\n",
      "        0.00000000e+00, 1.17479848e-35, 1.17438271e-35]], dtype=float32), array([1.17440804e-35, 1.17463095e-35, 1.17466640e-35, 1.17441564e-35,\n",
      "       1.17513519e-35, 1.17455103e-35, 1.17489118e-35, 1.17548481e-35,\n",
      "       1.17455103e-35, 1.17522523e-35, 1.17541600e-35, 1.17454837e-35,\n",
      "       1.17550332e-35, 1.17498538e-35, 1.17537109e-35, 1.17532704e-35,\n",
      "       1.17444140e-35, 1.17513634e-35, 1.17515772e-35, 1.17483392e-35,\n",
      "       1.17477653e-35, 2.01770244e-03, 1.17506014e-35, 1.17531075e-35,\n",
      "       1.17472049e-35, 1.17441449e-35, 1.17470270e-35, 4.55404806e-04,\n",
      "       1.17516927e-35, 1.17511460e-35, 1.17436463e-35, 1.17530336e-35,\n",
      "       1.17489118e-35, 1.17440804e-35, 1.17446421e-35, 1.17488680e-35,\n",
      "       1.17503668e-35, 1.17472049e-35, 1.17505713e-35, 1.17539276e-35,\n",
      "       1.17476907e-35, 1.17459214e-35, 1.17521612e-35, 1.17449743e-35,\n",
      "       1.17436843e-35, 1.17531599e-35, 1.17528047e-35, 1.17477072e-35,\n",
      "       1.17515061e-35, 1.17537496e-35, 1.17531599e-35, 1.17457592e-35,\n",
      "       1.17500102e-35, 1.17461079e-35, 1.17500102e-35, 1.17502534e-35,\n",
      "       1.17460276e-35, 1.17485423e-35, 1.17485423e-35, 1.84614892e-05,\n",
      "       1.17516927e-35, 1.17472078e-35, 1.17504084e-35, 1.17537109e-35,\n",
      "       1.17502534e-35, 1.17461079e-35, 1.17516927e-35, 1.17436477e-35,\n",
      "       3.01009150e-05, 1.17520830e-35, 1.17468835e-35, 1.17489118e-35,\n",
      "       1.17539276e-35, 1.17483392e-35, 1.17482897e-35, 1.17482352e-35,\n",
      "       2.70107514e-22, 1.17510685e-35, 1.17543215e-35, 1.17442382e-35,\n",
      "       1.17526541e-35, 1.17489118e-35, 1.17500102e-35, 1.17524883e-35,\n",
      "       1.17528047e-35, 1.17437955e-35, 1.17550318e-35, 1.17500131e-35,\n",
      "       1.17539276e-35, 1.17466224e-35, 1.17539276e-35, 1.17449779e-35,\n",
      "       1.17463095e-35, 1.17531599e-35, 1.17466640e-35, 1.17455103e-35,\n",
      "       1.17466640e-35, 1.17444219e-35, 1.17454837e-35, 1.17499758e-35,\n",
      "       1.17500102e-35, 1.17533830e-35, 1.17538573e-35, 1.17444140e-35,\n",
      "       1.17498538e-35, 1.17514638e-35, 1.17436463e-35, 1.17449743e-35,\n",
      "       1.17539276e-35, 1.17514638e-35, 1.17528047e-35, 1.17504084e-35,\n",
      "       1.17509601e-35, 1.17494520e-35, 1.17544915e-35, 1.17500102e-35,\n",
      "       1.17494520e-35, 1.17504931e-35, 1.17522523e-35, 1.17444140e-35,\n",
      "       1.17447943e-35, 1.17516138e-35, 1.17472049e-35, 1.17464329e-35,\n",
      "       1.17466640e-35, 1.17483392e-35, 1.17459214e-35, 1.17499313e-35,\n",
      "       1.17528047e-35, 1.17434892e-35, 1.17477653e-35, 1.17438802e-35,\n",
      "       1.17497935e-35, 1.17461079e-35, 1.17520421e-35, 1.17447943e-35,\n",
      "       1.17482539e-35, 2.20837595e-04, 1.17525364e-35, 1.17483392e-35,\n",
      "       1.17492691e-35, 1.17447943e-35, 1.17548467e-35, 1.17468835e-35,\n",
      "       1.17533830e-35, 1.17487188e-35, 1.17454443e-35, 1.17454443e-35,\n",
      "       1.17491371e-35, 1.17466640e-35, 1.17538192e-35, 3.53163981e-04,\n",
      "       1.17448983e-35, 1.17516927e-35, 1.17516927e-35, 1.17449743e-35,\n",
      "       1.17472078e-35, 1.17500131e-35, 1.17516927e-35, 1.17498538e-35,\n",
      "       1.17528047e-35, 1.17544341e-35, 1.17471066e-35, 1.17474467e-35,\n",
      "       1.17466640e-35, 1.17510369e-35, 1.17436463e-35, 1.17455103e-35,\n",
      "       1.17526541e-35, 1.17528047e-35, 1.17507801e-35, 1.17488680e-35,\n",
      "       1.17533830e-35, 1.17477653e-35, 1.17481627e-35, 1.17449743e-35,\n",
      "       1.17476132e-35, 1.17444140e-35, 1.17520421e-35, 1.28216846e-31,\n",
      "       1.17457592e-35, 1.17481269e-35, 1.78019836e-30, 1.17530336e-35,\n",
      "       1.17444140e-35, 1.17489118e-35, 1.17474467e-35, 1.17449743e-35,\n",
      "       1.17533830e-35, 1.17477638e-35, 1.17452233e-35, 1.17499313e-35,\n",
      "       1.17515772e-35, 1.17547362e-35, 1.17550318e-35, 1.17477072e-35,\n",
      "       1.17478133e-35, 1.17453295e-35, 1.17507801e-35, 1.17533342e-35],\n",
      "      dtype=float32), array([[1.17477638e-35, 1.17449779e-35, 1.17520887e-35, ...,\n",
      "        1.17530336e-35, 1.17543215e-35, 1.17447943e-35],\n",
      "       [1.17447943e-35, 1.17489118e-35, 1.17550605e-35, ...,\n",
      "        1.17493451e-35, 1.17511460e-35, 0.00000000e+00],\n",
      "       [1.17522150e-35, 1.17466640e-35, 1.17497935e-35, ...,\n",
      "        1.17537109e-35, 1.17533830e-35, 1.17472049e-35],\n",
      "       ...,\n",
      "       [1.17483392e-35, 1.17449743e-35, 1.17472049e-35, ...,\n",
      "        1.17472049e-35, 1.17452233e-35, 0.00000000e+00],\n",
      "       [1.17480745e-35, 1.17489154e-35, 1.17483392e-35, ...,\n",
      "        1.17494520e-35, 1.17536069e-35, 1.17461079e-35],\n",
      "       [1.17500102e-35, 1.17516927e-35, 1.17511460e-35, ...,\n",
      "        1.17505713e-35, 1.17494520e-35, 1.17526541e-35]], dtype=float32), array([1.17454443e-35, 1.17455103e-35, 1.17522494e-35, 1.27705106e-16,\n",
      "       1.17500102e-35, 1.17449779e-35, 8.13613224e-06, 1.17481627e-35,\n",
      "       1.17470270e-35, 1.17494147e-35, 1.17489118e-35, 1.18746702e-05,\n",
      "       1.17541600e-35, 1.17516489e-35, 1.17466640e-35, 1.17505713e-35,\n",
      "       1.17435150e-35, 1.17541600e-35, 1.17476132e-35, 1.17449743e-35,\n",
      "       1.17459214e-35, 1.17515061e-35, 1.17489118e-35, 1.17504084e-35,\n",
      "       5.78069807e-20, 1.17513519e-35, 1.14675897e-30, 1.17453740e-35,\n",
      "       1.17502534e-35, 1.17477638e-35, 1.17539276e-35, 1.17453295e-35,\n",
      "       1.17489118e-35, 1.17483392e-35, 1.17477323e-35, 1.17494520e-35,\n",
      "       6.94810104e-19, 1.17477638e-35, 1.17447943e-35, 1.17475543e-35,\n",
      "       1.17438802e-35, 1.17549765e-35, 1.17544915e-35, 1.17538874e-35,\n",
      "       1.17493451e-35, 1.17513634e-35, 1.17469854e-35, 1.54547954e-14,\n",
      "       1.34038028e-05, 1.17461079e-35, 3.42982004e-17, 9.12609593e-18,\n",
      "       1.17468720e-35, 1.17503697e-35, 2.45515230e-06, 4.32847810e-06,\n",
      "       8.14817326e-07, 1.17548890e-35, 1.17480092e-35, 1.17455103e-35,\n",
      "       1.17461079e-35, 1.17539276e-35, 1.17457592e-35, 1.17487956e-35,\n",
      "       1.17505713e-35, 1.17472049e-35, 1.17493681e-35, 1.17476132e-35,\n",
      "       3.08771931e-17, 1.17533830e-35, 1.75894306e-16, 1.17444140e-35,\n",
      "       1.17483392e-35, 1.17461079e-35, 9.15601257e-17, 1.17435150e-35,\n",
      "       1.17526541e-35, 1.17531075e-35, 2.01645526e-06, 1.17468835e-35,\n",
      "       1.17491371e-35, 1.17437582e-35, 1.17444233e-35, 1.17527610e-35,\n",
      "       8.94839275e-07, 1.89624882e-22, 4.71963880e-17, 1.17435150e-35,\n",
      "       1.17536069e-35, 1.17502534e-35, 5.69143076e-17, 1.17548890e-35,\n",
      "       1.17482625e-35, 1.17436843e-35, 1.17516927e-35, 1.17528047e-35,\n",
      "       1.17543215e-35, 1.17527610e-35, 1.17474467e-35, 7.97787507e-05,\n",
      "       1.17455103e-35, 3.94516646e-17, 1.74163724e-05, 1.17461079e-35,\n",
      "       1.17533830e-35, 1.17533830e-35, 1.17444233e-35, 1.17513634e-35,\n",
      "       1.17466015e-35, 1.17503697e-35, 4.96346418e-18, 9.88750803e-19,\n",
      "       1.17498538e-35, 1.17472049e-35, 1.17530336e-35, 1.17492275e-35,\n",
      "       1.17448732e-35, 5.54320974e-19, 1.17468835e-35, 1.17538874e-35,\n",
      "       5.33778461e-07, 1.17461079e-35, 1.17539412e-35, 1.17461079e-35,\n",
      "       1.17539276e-35, 1.17533773e-35, 9.71312616e-18, 1.17476132e-35,\n",
      "       1.17455103e-35, 1.17489118e-35, 5.38729101e-17, 1.17470270e-35,\n",
      "       1.17533342e-35, 1.67677626e-05, 2.25262106e-20, 1.17547362e-35,\n",
      "       1.17483392e-35, 1.17449743e-35, 5.61305706e-06, 1.17474467e-35,\n",
      "       1.17519237e-35, 1.17522494e-35, 1.17448732e-35, 1.17498538e-35,\n",
      "       1.17544915e-35, 1.17522523e-35, 1.17515061e-35, 1.17520421e-35,\n",
      "       1.17483392e-35, 1.17448983e-35, 1.17446421e-35, 1.17541600e-35,\n",
      "       1.17531613e-35, 1.17449743e-35, 2.30649677e-09, 1.17505713e-35,\n",
      "       4.47100820e-03, 1.17544915e-35, 1.17539276e-35, 1.17446421e-35,\n",
      "       1.17449743e-35, 1.02237175e-06, 1.17515061e-35, 1.17455103e-35,\n",
      "       1.17472078e-35, 1.17466640e-35, 1.17544915e-35, 1.17455103e-35,\n",
      "       1.17550318e-35, 1.17544915e-35, 1.17436843e-35, 5.30282909e-18,\n",
      "       1.17511460e-35, 1.17453740e-35, 1.17519811e-35, 3.70386597e-17,\n",
      "       1.17496572e-35, 1.17485423e-35, 1.17507801e-35, 1.17482352e-35,\n",
      "       1.17500102e-35, 1.17489118e-35, 1.17464853e-35, 1.17550332e-35,\n",
      "       1.17507801e-35, 1.17524683e-35, 1.17520421e-35, 1.17472049e-35,\n",
      "       1.17436843e-35, 1.17522494e-35, 3.65182837e-17, 1.17454837e-35,\n",
      "       1.17516927e-35, 1.17453740e-35, 1.17531685e-35, 1.17466640e-35,\n",
      "       1.17499586e-35, 1.17539276e-35, 1.17492691e-35, 7.42559314e-06,\n",
      "       1.17522523e-35, 1.17493451e-35, 8.26800961e-10, 1.17503668e-35,\n",
      "       1.17464329e-35, 1.17486614e-35, 1.17538874e-35, 1.17516927e-35,\n",
      "       1.07100150e-05, 1.17538874e-35, 1.17548890e-35, 1.17550332e-35,\n",
      "       1.17444140e-35, 1.17438802e-35, 1.02621061e-05, 1.17460190e-35,\n",
      "       1.17453740e-35, 1.17447943e-35, 1.17486614e-35, 1.17500102e-35,\n",
      "       1.17436843e-35, 1.17533830e-35, 1.17464853e-35, 1.17466640e-35,\n",
      "       1.17536069e-35, 1.17441930e-35, 1.74159850e-05, 1.57812743e-17,\n",
      "       1.17548890e-35, 1.17479848e-35, 8.94224172e-07, 1.06681464e-09,\n",
      "       1.17515061e-35, 1.17476907e-35, 1.17548890e-35, 1.17472049e-35,\n",
      "       1.17511775e-35, 1.17505713e-35, 7.25192831e-06, 1.17471066e-35,\n",
      "       1.17480092e-35, 1.17516066e-35, 1.17481627e-35, 1.17476132e-35,\n",
      "       1.17511460e-35, 1.17466826e-35, 1.36091315e-16, 1.17477638e-35,\n",
      "       3.44913078e-18, 1.35672121e-06, 1.17526096e-35, 1.17533342e-35,\n",
      "       1.17449743e-35, 1.17476132e-35, 1.17447491e-35, 1.17509601e-35,\n",
      "       1.17548467e-35, 8.73637532e-07, 1.17454443e-35, 1.17461079e-35,\n",
      "       1.17539276e-35, 1.17458862e-35, 1.17468835e-35, 1.17533830e-35,\n",
      "       1.17483392e-35, 1.17479848e-35, 1.17459214e-35, 1.17511460e-35,\n",
      "       1.17466697e-35, 1.67958031e-16, 1.17544944e-35, 1.17476175e-35,\n",
      "       1.17526067e-35, 1.17520830e-35, 1.17544915e-35, 1.17491371e-35,\n",
      "       1.17475572e-35, 1.17547362e-35, 1.47192952e-17, 1.17516927e-35,\n",
      "       1.17519237e-35, 1.17544915e-35, 1.17486112e-35, 1.79334365e-05,\n",
      "       1.17486614e-35, 1.17547362e-35, 7.91343496e-07, 1.17455103e-35,\n",
      "       1.83442023e-25, 9.59941886e-08, 1.17440804e-35, 1.17516927e-35,\n",
      "       1.17459214e-35, 1.17454615e-35, 8.89266369e-11, 1.17497340e-35,\n",
      "       1.17505713e-35, 8.37678272e-06, 1.17548524e-35, 1.17536069e-35],\n",
      "      dtype=float32), array([[1.17519122e-35, 1.17530336e-35, 1.17487188e-35, ...,\n",
      "        1.17528047e-35, 1.17544915e-35, 1.17520421e-35],\n",
      "       [1.17489118e-35, 1.17492691e-35, 1.17482352e-35, ...,\n",
      "        1.17526541e-35, 1.17532015e-35, 1.17548890e-35],\n",
      "       [1.17519811e-35, 1.17483392e-35, 0.00000000e+00, ...,\n",
      "        0.00000000e+00, 1.17500102e-35, 1.17505713e-35],\n",
      "       ...,\n",
      "       [0.00000000e+00, 1.17483392e-35, 1.21092144e-05, ...,\n",
      "        7.01427730e-15, 1.17481627e-35, 1.17476175e-35],\n",
      "       [1.17468835e-35, 1.17449743e-35, 1.17464329e-35, ...,\n",
      "        1.17439075e-35, 1.17465599e-35, 1.17468835e-35],\n",
      "       [0.00000000e+00, 1.17441930e-35, 0.00000000e+00, ...,\n",
      "        0.00000000e+00, 1.17481627e-35, 1.17505713e-35]], dtype=float32), array([1.17542131e-35, 1.17447491e-35, 1.73784187e-07, 1.17539276e-35,\n",
      "       1.17435150e-35, 7.81003166e-07, 1.17494520e-35, 1.17444140e-35,\n",
      "       1.17531599e-35, 6.72821280e-24, 1.17539276e-35, 1.17492275e-35,\n",
      "       1.17550318e-35, 1.17492691e-35, 1.17439649e-35, 1.17532984e-35,\n",
      "       1.17542712e-35, 1.17487956e-35, 1.17541600e-35, 1.17548890e-35,\n",
      "       1.17442382e-35, 1.55566377e-28, 1.17511460e-35, 1.48586823e-24,\n",
      "       2.44516262e-15, 1.17516927e-35, 1.17449779e-35, 4.77939784e-06,\n",
      "       2.83217336e-19, 1.17504084e-35, 2.83229582e-07, 1.17489118e-35,\n",
      "       1.17547835e-35, 4.37250611e-24, 1.17511460e-35, 6.22404521e-16,\n",
      "       9.32899294e-32, 1.17550318e-35, 1.17515061e-35, 1.17499586e-35,\n",
      "       1.17544255e-35, 1.17521612e-35, 1.17472049e-35, 1.17480745e-35,\n",
      "       1.17438802e-35, 1.17472049e-35, 1.17539276e-35, 1.17478284e-35,\n",
      "       1.17526311e-35, 1.94648809e-27, 1.17434892e-35, 2.05622440e-28,\n",
      "       1.46660226e-35, 1.17542741e-35, 1.17447003e-35, 1.17522494e-35,\n",
      "       1.62842939e-24, 7.78637202e-28, 2.04172254e-19, 1.17500131e-35,\n",
      "       1.17500131e-35, 1.17483392e-35, 1.17533830e-35, 1.07414031e-20,\n",
      "       5.64743914e-07, 1.17447943e-35, 1.17524883e-35, 6.14033127e-07,\n",
      "       1.17519237e-35, 1.17476562e-35, 2.45540530e-24, 1.17500102e-35,\n",
      "       1.17449327e-35, 1.17533830e-35, 1.17548890e-35, 3.03697813e-16,\n",
      "       1.17481269e-35, 1.36695212e-06, 1.17487188e-35, 1.17528047e-35,\n",
      "       1.17516489e-35, 1.17521612e-35, 4.05810362e-16, 1.17448983e-35,\n",
      "       1.17516927e-35, 1.17452233e-35, 1.17468857e-35, 1.17504084e-35,\n",
      "       1.17463095e-35, 8.66989018e-33, 2.13539618e-24, 6.75919197e-29,\n",
      "       1.17544915e-35, 1.17505713e-35, 1.17477638e-35, 7.46070517e-27,\n",
      "       6.10805146e-16, 1.17500131e-35, 1.17498538e-35, 1.17483392e-35,\n",
      "       1.17520830e-35, 1.17541600e-35, 1.17533830e-35, 1.17511460e-35,\n",
      "       1.17477638e-35, 1.15476936e-07, 1.17461625e-35, 1.17487188e-35,\n",
      "       1.79359674e-07, 1.32053689e-24, 1.17498538e-35, 9.62519986e-28,\n",
      "       1.17481627e-35, 1.17442382e-35, 1.17477638e-35, 1.17454443e-35,\n",
      "       1.17507614e-35, 1.17521913e-35, 9.99103949e-16, 2.44268525e-31,\n",
      "       1.17544915e-35, 1.17521612e-35, 1.17438802e-35, 1.17438271e-35,\n",
      "       2.57001327e-32, 1.19480553e-27, 1.17500102e-35, 1.17464853e-35,\n",
      "       1.17522523e-35, 1.17532015e-35, 1.17472049e-35, 1.17457592e-35,\n",
      "       1.17464853e-35, 1.17471669e-35, 1.17463146e-35, 1.17516991e-35,\n",
      "       1.17520421e-35, 2.40394769e-15, 1.05854136e-27, 1.17544341e-35,\n",
      "       1.17483392e-35, 1.02468291e-02, 1.17487956e-35, 1.17488680e-35,\n",
      "       1.17548467e-35, 1.17526541e-35, 1.17477638e-35, 1.17527610e-35,\n",
      "       3.50377604e-07, 1.17487956e-35, 1.17461079e-35, 1.64424665e-24,\n",
      "       7.19883085e-16, 1.17505713e-35, 9.82711301e-27, 1.17439448e-35,\n",
      "       1.17472049e-35, 1.17475371e-35, 8.97034464e-19, 1.17461079e-35,\n",
      "       1.17513634e-35, 4.58387119e-27, 1.17538192e-35, 1.40435415e-24,\n",
      "       1.17453740e-35, 1.17539276e-35, 2.58877265e-07, 1.17497935e-35,\n",
      "       1.17496788e-35, 9.25523864e-07, 1.17447003e-35, 5.79219857e-17,\n",
      "       2.47838045e-03, 1.17434892e-35, 1.17442382e-35, 1.16427617e-27,\n",
      "       1.44854357e-24, 1.17526139e-35, 1.17483392e-35, 1.17455103e-35,\n",
      "       1.17459214e-35, 1.17531204e-35, 1.17474467e-35, 1.17452075e-35,\n",
      "       3.02631735e-24, 1.17493681e-35, 1.17491572e-35, 5.06043952e-16,\n",
      "       1.17522523e-35, 1.17547362e-35, 1.17505885e-35, 2.21520809e-27,\n",
      "       5.38444464e-28, 1.18092601e-06, 5.01173628e-24, 1.17532072e-35,\n",
      "       1.68767219e-27, 4.02588661e-15, 1.17472049e-35, 1.66181321e-28],\n",
      "      dtype=float32), array([[1.17516927e-35],\n",
      "       [1.17494520e-35],\n",
      "       [6.07404053e-01],\n",
      "       [1.17475572e-35],\n",
      "       [1.17466640e-35],\n",
      "       [3.51218700e+00],\n",
      "       [1.17437582e-35],\n",
      "       [1.17522494e-35],\n",
      "       [1.17447943e-35],\n",
      "       [6.45892646e-24],\n",
      "       [1.17520421e-35],\n",
      "       [1.17444140e-35],\n",
      "       [1.17514638e-35],\n",
      "       [1.17516489e-35],\n",
      "       [1.17483479e-35],\n",
      "       [1.17507801e-35],\n",
      "       [1.17517034e-35],\n",
      "       [1.17522494e-35],\n",
      "       [1.17480092e-35],\n",
      "       [1.17458862e-35],\n",
      "       [1.17516927e-35],\n",
      "       [3.00025558e-26],\n",
      "       [7.32505402e-34],\n",
      "       [2.90805179e-23],\n",
      "       [3.25449723e-10],\n",
      "       [1.17522494e-35],\n",
      "       [1.17550318e-35],\n",
      "       [1.75875628e+00],\n",
      "       [2.11017546e-17],\n",
      "       [1.17503668e-35],\n",
      "       [1.41172481e+00],\n",
      "       [1.17527610e-35],\n",
      "       [1.17458905e-35],\n",
      "       [2.29215290e-23],\n",
      "       [1.17440804e-35],\n",
      "       [6.99168024e-12],\n",
      "       [8.50132561e-31],\n",
      "       [1.17483392e-35],\n",
      "       [1.17449743e-35],\n",
      "       [1.17479848e-35],\n",
      "       [1.17532015e-35],\n",
      "       [1.17453338e-35],\n",
      "       [1.17511460e-35],\n",
      "       [1.17476132e-35],\n",
      "       [1.17453295e-35],\n",
      "       [1.17435150e-35],\n",
      "       [1.17472049e-35],\n",
      "       [1.17506904e-35],\n",
      "       [1.17436477e-35],\n",
      "       [1.21773527e-27],\n",
      "       [1.17461079e-35],\n",
      "       [4.03871477e-27],\n",
      "       [1.17489118e-35],\n",
      "       [1.17516927e-35],\n",
      "       [1.17453740e-35],\n",
      "       [1.17466640e-35],\n",
      "       [1.26842120e-23],\n",
      "       [8.23028674e-27],\n",
      "       [1.06863083e-17],\n",
      "       [1.17461079e-35],\n",
      "       [1.17482897e-35],\n",
      "       [1.17488680e-35],\n",
      "       [1.17519237e-35],\n",
      "       [1.06938207e-19],\n",
      "       [9.61963058e-01],\n",
      "       [1.17524883e-35],\n",
      "       [1.17507801e-35],\n",
      "       [3.63275194e+00],\n",
      "       [1.17483392e-35],\n",
      "       [1.17517379e-35],\n",
      "       [1.88535327e-23],\n",
      "       [1.17515061e-35],\n",
      "       [1.17505713e-35],\n",
      "       [1.17488680e-35],\n",
      "       [1.17515061e-35],\n",
      "       [4.50117611e-14],\n",
      "       [1.17477638e-35],\n",
      "       [3.89652944e+00],\n",
      "       [1.17533830e-35],\n",
      "       [1.17469854e-35],\n",
      "       [1.17455103e-35],\n",
      "       [1.17446421e-35],\n",
      "       [5.56180380e-10],\n",
      "       [1.17528047e-35],\n",
      "       [1.17500102e-35],\n",
      "       [1.17483392e-35],\n",
      "       [1.17511460e-35],\n",
      "       [1.17496687e-35],\n",
      "       [1.17448983e-35],\n",
      "       [2.76326084e-33],\n",
      "       [9.44167659e-24],\n",
      "       [5.62999638e-29],\n",
      "       [1.17454837e-35],\n",
      "       [1.17522494e-35],\n",
      "       [1.17547362e-35],\n",
      "       [1.91626257e-23],\n",
      "       [7.33855386e-14],\n",
      "       [1.17444140e-35],\n",
      "       [1.17452233e-35],\n",
      "       [1.17522494e-35],\n",
      "       [1.17494520e-35],\n",
      "       [1.17441959e-35],\n",
      "       [1.17459214e-35],\n",
      "       [1.17530336e-35],\n",
      "       [1.17528047e-35],\n",
      "       [8.97334754e-01],\n",
      "       [1.17538874e-35],\n",
      "       [1.17532015e-35],\n",
      "       [4.32510257e-01],\n",
      "       [2.92076886e-23],\n",
      "       [1.17539276e-35],\n",
      "       [1.97987717e-27],\n",
      "       [1.17539276e-35],\n",
      "       [1.17463095e-35],\n",
      "       [1.17436843e-35],\n",
      "       [1.17519811e-35],\n",
      "       [1.17477323e-35],\n",
      "       [1.17497541e-35],\n",
      "       [5.73444126e-10],\n",
      "       [2.07840762e-29],\n",
      "       [1.17505713e-35],\n",
      "       [1.17532704e-35],\n",
      "       [1.17477846e-35],\n",
      "       [1.17444140e-35],\n",
      "       [1.79230637e-29],\n",
      "       [4.77426262e-26],\n",
      "       [1.17548890e-35],\n",
      "       [1.17494520e-35],\n",
      "       [1.17494520e-35],\n",
      "       [1.17491371e-35],\n",
      "       [1.17448732e-35],\n",
      "       [1.17537496e-35],\n",
      "       [1.17435150e-35],\n",
      "       [1.17515061e-35],\n",
      "       [1.17436843e-35],\n",
      "       [1.17485423e-35],\n",
      "       [1.17528047e-35],\n",
      "       [3.40536516e-10],\n",
      "       [1.74649644e-27],\n",
      "       [1.17544915e-35],\n",
      "       [1.17532984e-35],\n",
      "       [2.75221920e+00],\n",
      "       [1.17504084e-35],\n",
      "       [1.17466640e-35],\n",
      "       [1.17482897e-35],\n",
      "       [1.17477638e-35],\n",
      "       [1.17504751e-35],\n",
      "       [1.17547362e-35],\n",
      "       [2.24074920e-05],\n",
      "       [1.17476132e-35],\n",
      "       [1.17436463e-35],\n",
      "       [2.34277694e-23],\n",
      "       [1.86336974e-10],\n",
      "       [1.17525364e-35],\n",
      "       [1.66881464e-27],\n",
      "       [1.17482252e-35],\n",
      "       [1.17550318e-35],\n",
      "       [1.17452477e-35],\n",
      "       [5.90111373e-19],\n",
      "       [1.17530020e-35],\n",
      "       [2.01676921e-33],\n",
      "       [2.43788736e-25],\n",
      "       [1.17533830e-35],\n",
      "       [2.05155443e-23],\n",
      "       [1.17449743e-35],\n",
      "       [1.17452915e-35],\n",
      "       [5.16925156e-01],\n",
      "       [1.17522494e-35],\n",
      "       [1.17488680e-35],\n",
      "       [2.94540167e+00],\n",
      "       [1.17466640e-35],\n",
      "       [6.63518601e-15],\n",
      "       [2.12385148e-01],\n",
      "       [1.17500102e-35],\n",
      "       [1.17488343e-35],\n",
      "       [1.17325873e-26],\n",
      "       [1.50509975e-23],\n",
      "       [1.17437582e-35],\n",
      "       [1.17502312e-35],\n",
      "       [1.17457592e-35],\n",
      "       [1.17468835e-35],\n",
      "       [1.17442382e-35],\n",
      "       [1.17466015e-35],\n",
      "       [1.17433428e-35],\n",
      "       [1.74803704e-23],\n",
      "       [2.90860888e-33],\n",
      "       [1.17439340e-35],\n",
      "       [2.64042752e-14],\n",
      "       [1.17511460e-35],\n",
      "       [1.17528047e-35],\n",
      "       [1.17521841e-35],\n",
      "       [8.29067235e-26],\n",
      "       [9.85902647e-30],\n",
      "       [3.46505928e+00],\n",
      "       [2.37896594e-23],\n",
      "       [1.17494563e-35],\n",
      "       [8.76746404e-27],\n",
      "       [1.00067421e-09],\n",
      "       [1.17438271e-35],\n",
      "       [1.83288118e-26]], dtype=float32), array([0.02795914], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(optimizer2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
