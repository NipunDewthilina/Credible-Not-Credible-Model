{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Input libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import keras\r\n",
    "import numpy\r\n",
    "import pandas\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense\r\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.model_selection import StratifiedKFold\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data input"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Importing the dataset\r\n",
    "dataset = pd.read_csv('default of credit card clients.csv')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import pandas as pd\r\n",
    "from sklearn import preprocessing"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# X and Y distribution of dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "X = dataset.iloc[:, 1:24].values\r\n",
    "y = dataset.iloc[:, 24].values\r\n",
    "X.shape,y.shape\r\n",
    "type(y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "X.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(30000, 23)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import pandas as pd\r\n",
    "from sklearn import preprocessing\r\n",
    "\r\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\r\n",
    "X = min_max_scaler.fit_transform(X)\r\n",
    "df = pd.DataFrame(X)\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             0    1         2         3         4    5    6    7    8    9   \\\n",
       "0      0.010101  1.0  0.333333  0.333333  0.051724  0.4  0.4  0.1  0.1  0.0   \n",
       "1      0.111111  1.0  0.333333  0.666667  0.086207  0.1  0.4  0.2  0.2  0.2   \n",
       "2      0.080808  1.0  0.333333  0.666667  0.224138  0.2  0.2  0.2  0.2  0.2   \n",
       "3      0.040404  1.0  0.333333  0.333333  0.275862  0.2  0.2  0.2  0.2  0.2   \n",
       "4      0.040404  0.0  0.333333  0.333333  0.620690  0.1  0.2  0.1  0.2  0.2   \n",
       "...         ...  ...       ...       ...       ...  ...  ...  ...  ...  ...   \n",
       "29995  0.212121  0.0  0.500000  0.333333  0.310345  0.2  0.2  0.2  0.2  0.2   \n",
       "29996  0.141414  0.0  0.500000  0.666667  0.379310  0.1  0.1  0.1  0.1  0.2   \n",
       "29997  0.020202  0.0  0.333333  0.666667  0.275862  0.6  0.5  0.4  0.1  0.2   \n",
       "29998  0.070707  0.0  0.500000  0.333333  0.344828  0.3  0.1  0.2  0.2  0.2   \n",
       "29999  0.040404  0.0  0.333333  0.333333  0.431034  0.2  0.2  0.2  0.2  0.2   \n",
       "\n",
       "       ...        13        14        15        16        17        18  \\\n",
       "0      ...  0.086723  0.160138  0.080648  0.260979  0.000000  0.000409   \n",
       "1      ...  0.087817  0.163220  0.084074  0.263485  0.000000  0.000594   \n",
       "2      ...  0.093789  0.173637  0.095470  0.272928  0.001738  0.000891   \n",
       "3      ...  0.113407  0.186809  0.109363  0.283685  0.002290  0.001199   \n",
       "4      ...  0.106020  0.179863  0.099633  0.275681  0.002290  0.021779   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "29995  ...  0.200746  0.243036  0.111622  0.273259  0.009730  0.011875   \n",
       "29996  ...  0.088267  0.168596  0.085794  0.260979  0.002103  0.002094   \n",
       "29997  ...  0.087859  0.179805  0.101057  0.275854  0.000000  0.000000   \n",
       "29998  ...  0.128239  0.209850  0.092403  0.298591  0.098334  0.002024   \n",
       "29999  ...  0.113667  0.194553  0.112803  0.272746  0.002379  0.001069   \n",
       "\n",
       "             19        20        21        22  \n",
       "0      0.000000  0.000000  0.000000  0.000000  \n",
       "1      0.001116  0.001610  0.000000  0.003783  \n",
       "2      0.001116  0.001610  0.002345  0.009458  \n",
       "3      0.001339  0.001771  0.002506  0.001892  \n",
       "4      0.011160  0.014493  0.001615  0.001284  \n",
       "...         ...       ...       ...       ...  \n",
       "29995  0.005583  0.004907  0.011723  0.001892  \n",
       "29996  0.010042  0.000208  0.000000  0.000000  \n",
       "29997  0.024552  0.006763  0.004689  0.005864  \n",
       "29998  0.001315  0.003101  0.124174  0.003412  \n",
       "29999  0.001596  0.001610  0.002345  0.001892  \n",
       "\n",
       "[30000 rows x 23 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086723</td>\n",
       "      <td>0.160138</td>\n",
       "      <td>0.080648</td>\n",
       "      <td>0.260979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>0.163220</td>\n",
       "      <td>0.084074</td>\n",
       "      <td>0.263485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.080808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.224138</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093789</td>\n",
       "      <td>0.173637</td>\n",
       "      <td>0.095470</td>\n",
       "      <td>0.272928</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.009458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113407</td>\n",
       "      <td>0.186809</td>\n",
       "      <td>0.109363</td>\n",
       "      <td>0.283685</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.001892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106020</td>\n",
       "      <td>0.179863</td>\n",
       "      <td>0.099633</td>\n",
       "      <td>0.275681</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.021779</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.001284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200746</td>\n",
       "      <td>0.243036</td>\n",
       "      <td>0.111622</td>\n",
       "      <td>0.273259</td>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.001892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0.141414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088267</td>\n",
       "      <td>0.168596</td>\n",
       "      <td>0.085794</td>\n",
       "      <td>0.260979</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.010042</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087859</td>\n",
       "      <td>0.179805</td>\n",
       "      <td>0.101057</td>\n",
       "      <td>0.275854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024552</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.005864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0.070707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128239</td>\n",
       "      <td>0.209850</td>\n",
       "      <td>0.092403</td>\n",
       "      <td>0.298591</td>\n",
       "      <td>0.098334</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.124174</td>\n",
       "      <td>0.003412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113667</td>\n",
       "      <td>0.194553</td>\n",
       "      <td>0.112803</td>\n",
       "      <td>0.272746</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.001892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 23 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "X[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.11111111e-01, 1.00000000e+00, 3.33333333e-01, 6.66666667e-01,\n",
       "       8.62068966e-02, 1.00000000e-01, 4.00000000e-01, 2.00000000e-01,\n",
       "       2.00000000e-01, 2.00000000e-01, 4.00000000e-01, 1.48892434e-01,\n",
       "       6.78575089e-02, 8.78171337e-02, 1.63219937e-01, 8.40739510e-02,\n",
       "       2.63484742e-01, 0.00000000e+00, 5.93732912e-04, 1.11602161e-03,\n",
       "       1.61030596e-03, 0.00000000e+00, 3.78310691e-03])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "X[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.11111111e-01, 1.00000000e+00, 3.33333333e-01, 6.66666667e-01,\n",
       "       8.62068966e-02, 1.00000000e-01, 4.00000000e-01, 2.00000000e-01,\n",
       "       2.00000000e-01, 2.00000000e-01, 4.00000000e-01, 1.48892434e-01,\n",
       "       6.78575089e-02, 8.78171337e-02, 1.63219937e-01, 8.40739510e-02,\n",
       "       2.63484742e-01, 0.00000000e+00, 5.93732912e-04, 1.11602161e-03,\n",
       "       1.61030596e-03, 0.00000000e+00, 3.78310691e-03])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert Categorical to Numerical Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# from sklearn.preprocessing import LabelEncoder, OneHotEncoder\r\n",
    "# #for country column\r\n",
    "# labelencoder_X_1 = LabelEncoder()\r\n",
    "# X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\r\n",
    "# #for gender column\r\n",
    "# labelencoder_X_2 = LabelEncoder()\r\n",
    "# X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\r\n",
    "# np.shape(X)\r\n",
    "# X"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Learning Baseline Model-Using Buildin Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# baseline model(using 1 connected layer and one 1 output layer)\r\n",
    "def create_baseline():\r\n",
    "# create model\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(30, input_dim=23, kernel_initializer='normal', activation='relu'))\r\n",
    "    model.add(Dense(23, input_dim=30, kernel_initializer='normal', activation='relu'))\r\n",
    "    model.add(Dense(30, input_dim=23, kernel_initializer='normal', activation='relu'))\r\n",
    "    model.add(Dense(30, input_dim=23, kernel_initializer='normal', activation='relu'))\r\n",
    "    model.add(Dense(1, kernel_initializer='random_normal', activation='tanh'))\r\n",
    "    # Compile model\r\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "seed = 7\r\n",
    "numpy.random.seed(seed)\r\n",
    "# evaluate model with standardized dataset\r\n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=50, batch_size=5, verbose=0)\r\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\r\n",
    "results = cross_val_score(estimator, X, y, cv=kfold)\r\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Learning Model-Using Sequential Module\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\r\n",
    "X_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[4.74747475e-01, 0.00000000e+00, 3.33333333e-01, ...,\n",
       "        1.93236715e-02, 2.93063309e-02, 2.30769522e-02],\n",
       "       [2.02020202e-01, 1.00000000e+00, 1.66666667e-01, ...,\n",
       "        9.49436393e-03, 0.00000000e+00, 1.70024174e-01],\n",
       "       [2.22222222e-01, 1.00000000e+00, 3.33333333e-01, ...,\n",
       "        0.00000000e+00, 3.53528131e-02, 1.51324277e-02],\n",
       "       ...,\n",
       "       [1.91919192e-01, 0.00000000e+00, 3.33333333e-01, ...,\n",
       "        1.00756844e-02, 1.55511114e-02, 1.15668494e-02],\n",
       "       [1.91919192e-01, 1.00000000e+00, 3.33333333e-01, ...,\n",
       "        4.83091787e-03, 7.03351941e-03, 5.67466037e-03],\n",
       "       [4.04040404e-02, 1.00000000e+00, 5.00000000e-01, ...,\n",
       "        4.83091787e-04, 4.68901294e-04, 9.45776729e-04]])"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "type(X_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "X_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[4.74747475e-01, 0.00000000e+00, 3.33333333e-01, ...,\n",
       "        1.93236715e-02, 2.93063309e-02, 2.30769522e-02],\n",
       "       [2.02020202e-01, 1.00000000e+00, 1.66666667e-01, ...,\n",
       "        9.49436393e-03, 0.00000000e+00, 1.70024174e-01],\n",
       "       [2.22222222e-01, 1.00000000e+00, 3.33333333e-01, ...,\n",
       "        0.00000000e+00, 3.53528131e-02, 1.51324277e-02],\n",
       "       ...,\n",
       "       [1.91919192e-01, 0.00000000e+00, 3.33333333e-01, ...,\n",
       "        1.00756844e-02, 1.55511114e-02, 1.15668494e-02],\n",
       "       [1.91919192e-01, 1.00000000e+00, 3.33333333e-01, ...,\n",
       "        4.83091787e-03, 7.03351941e-03, 5.67466037e-03],\n",
       "       [4.04040404e-02, 1.00000000e+00, 5.00000000e-01, ...,\n",
       "        4.83091787e-04, 4.68901294e-04, 9.45776729e-04]])"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "y.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(30000,)"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "import tensorflow as tf\r\n",
    "# import keras\r\n",
    "# from keras import layers\r\n",
    "# from keras import models\r\n",
    "# from keras import utils\r\n",
    "# from keras.layers import Dense\r\n",
    "# from keras.models import Sequential\r\n",
    "# from keras.layers import Flatten\r\n",
    "# from keras.layers import Dropout\r\n",
    "# from keras.layers import Activation\r\n",
    "# from keras.regularizers import l2\r\n",
    "# from keras.optimizers import SGD\r\n",
    "# from keras.optimizers import RMSprop\r\n",
    "# from keras import datasets\r\n",
    "\r\n",
    "# from keras.callbacks import LearningRateScheduler\r\n",
    "# from keras.callbacks import History\r\n",
    "\r\n",
    "# from keras import losses\r\n",
    "# from sklearn.utils import shuffle\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras.optimizers import SGD\r\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\r\n",
    "print(tf.__version__)\r\n",
    "print(tf.keras.__version__)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-cf00eaafc648>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# from keras import layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# from keras import models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# from keras import utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\r\n",
    "    initial_learning_rate=1e-2,\r\n",
    "    decay_steps=10000,\r\n",
    "    decay_rate=0.1)\r\n",
    "optimizer1 = keras.optimizers.SGD(learning_rate=lr_schedule)\r\n",
    "optimizer2 = keras.optimizers.Adam(learning_rate = 0.001,beta_1=0.9,\r\n",
    "    beta_2=0.999,\r\n",
    "    epsilon=1e-07)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{loss:.2f}.h5'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Initializing Neural Network\n",
    "Model = keras.Sequential()\n",
    "Model.add(Dense(100, input_dim = 23, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
    "# Adding the second hidden layer\n",
    "Model.add(Dense(200, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
    "# Adding the third hidden layer\n",
    "Model.add(Dense(300, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "# Adding the Fourth hidden layer\n",
    "Model.add(Dense(200, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
    "# Adding the Fifth layer\n",
    "Model.add(Dense(200, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
    "# Adding the output layer\n",
    "Model.add(Dense(1, kernel_initializer = 'random_uniform', activation = 'sigmoid'))\n",
    "# Compiling Neural Network\n",
    "Model.compile(optimizer = optimizer2, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#fitting the neural Network\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "Model.fit(X_train, y_train, batch_size = 15, epochs = 50)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "score = Model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Accuracy: ', score[1]*100)\n",
    "print( 'loss:', score[0]*100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(optimizer2.get_weights())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pytorch Implementation\n",
    "## Import necessary libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "import torch\n",
    "# import keras\n",
    "import numpy\n",
    "import pandas\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Process Start"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "X_train"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-931765772341>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "y_train"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f56205002e60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "X_test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.01010101e-02, 1.00000000e+00, 1.66666667e-01, ...,\n",
       "        1.61030596e-03, 1.23860277e-02, 0.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00, 3.33333333e-01, ...,\n",
       "        4.49275362e-04, 2.34450647e-03, 1.51324277e-03],\n",
       "       [4.04040404e-02, 0.00000000e+00, 1.66666667e-01, ...,\n",
       "        1.93236715e-03, 9.39678193e-03, 8.33607609e-03],\n",
       "       ...,\n",
       "       [2.02020202e-02, 0.00000000e+00, 3.33333333e-01, ...,\n",
       "        1.34460548e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.04040404e-02, 1.00000000e+00, 3.33333333e-01, ...,\n",
       "        2.41545894e-03, 2.81340776e-03, 2.45901949e-03],\n",
       "       [2.92929293e-01, 1.00000000e+00, 1.66666667e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "y_test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "x_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert to Tensors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "X_train = torch.tensor(X_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-85-af21c8a8097d>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "X_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[4.7475e-01, 0.0000e+00, 3.3333e-01,  ..., 1.9324e-02, 2.9306e-02,\n",
       "         2.3077e-02],\n",
       "        [2.0202e-01, 1.0000e+00, 1.6667e-01,  ..., 9.4944e-03, 0.0000e+00,\n",
       "         1.7002e-01],\n",
       "        [2.2222e-01, 1.0000e+00, 3.3333e-01,  ..., 0.0000e+00, 3.5353e-02,\n",
       "         1.5132e-02],\n",
       "        ...,\n",
       "        [1.9192e-01, 0.0000e+00, 3.3333e-01,  ..., 1.0076e-02, 1.5551e-02,\n",
       "         1.1567e-02],\n",
       "        [1.9192e-01, 1.0000e+00, 3.3333e-01,  ..., 4.8309e-03, 7.0335e-03,\n",
       "         5.6747e-03],\n",
       "        [4.0404e-02, 1.0000e+00, 5.0000e-01,  ..., 4.8309e-04, 4.6890e-04,\n",
       "         9.4578e-04]], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "y_train = torch.tensor(y_train)\n",
    "X_test = torch.tensor(X_test)\n",
    "y_test = torch.tensor(y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-87-0b2077a32e82>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train)\n",
      "<ipython-input-87-0b2077a32e82>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test)\n",
      "<ipython-input-87-0b2077a32e82>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "y_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "y_test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}