{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "keras+binary+classfication_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Bd8SswENObD7"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Input libraries"
      ],
      "metadata": {
        "id": "H826CHWXObDj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import keras\n",
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "metadata": {
        "id": "jhKb3xzpObDn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "outputs": [],
      "metadata": {
        "id": "sT2nt1wDObDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data input"
      ],
      "metadata": {
        "id": "BBK3_GXtObDo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# Importing the dataset\n",
        "dataset = pd.read_csv('default of credit card clients.csv')\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "QBT8ES5MObDo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "8BZCS8EMOv4S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing"
      ],
      "outputs": [],
      "metadata": {
        "id": "IHcH4NV1ObDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# X and Y distribution of dataset"
      ],
      "metadata": {
        "id": "dUgQEfi8ObDp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "X = dataset.iloc[:, 1:24].values\n",
        "y = dataset.iloc[:, 24].values\n",
        "X.shape,y.shape\n",
        "type(y)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q4UbP-AObDp",
        "outputId": "f3dd4e36-e884-4a64-bcff-4d193ee87d67"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "X.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX79O2KiObDr",
        "outputId": "82aa8c8a-fd65-4d7d-8855-a562fe16a2bf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X = min_max_scaler.fit_transform(X)\n",
        "df = pd.DataFrame(X)\n",
        "df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0    1         2   ...        20        21        22\n",
              "0      0.010101  1.0  0.333333  ...  0.000000  0.000000  0.000000\n",
              "1      0.111111  1.0  0.333333  ...  0.001610  0.000000  0.003783\n",
              "2      0.080808  1.0  0.333333  ...  0.001610  0.002345  0.009458\n",
              "3      0.040404  1.0  0.333333  ...  0.001771  0.002506  0.001892\n",
              "4      0.040404  0.0  0.333333  ...  0.014493  0.001615  0.001284\n",
              "...         ...  ...       ...  ...       ...       ...       ...\n",
              "29995  0.212121  0.0  0.500000  ...  0.004907  0.011723  0.001892\n",
              "29996  0.141414  0.0  0.500000  ...  0.000208  0.000000  0.000000\n",
              "29997  0.020202  0.0  0.333333  ...  0.006763  0.004689  0.005864\n",
              "29998  0.070707  0.0  0.500000  ...  0.003101  0.124174  0.003412\n",
              "29999  0.040404  0.0  0.333333  ...  0.001610  0.002345  0.001892\n",
              "\n",
              "[30000 rows x 23 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.010101</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.051724</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.149982</td>\n",
              "      <td>0.069164</td>\n",
              "      <td>0.086723</td>\n",
              "      <td>0.160138</td>\n",
              "      <td>0.080648</td>\n",
              "      <td>0.260979</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000409</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.111111</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.086207</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.148892</td>\n",
              "      <td>0.067858</td>\n",
              "      <td>0.087817</td>\n",
              "      <td>0.163220</td>\n",
              "      <td>0.084074</td>\n",
              "      <td>0.263485</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000594</td>\n",
              "      <td>0.001116</td>\n",
              "      <td>0.001610</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.080808</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.224138</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.172392</td>\n",
              "      <td>0.079532</td>\n",
              "      <td>0.093789</td>\n",
              "      <td>0.173637</td>\n",
              "      <td>0.095470</td>\n",
              "      <td>0.272928</td>\n",
              "      <td>0.001738</td>\n",
              "      <td>0.000891</td>\n",
              "      <td>0.001116</td>\n",
              "      <td>0.001610</td>\n",
              "      <td>0.002345</td>\n",
              "      <td>0.009458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.040404</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.275862</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.188100</td>\n",
              "      <td>0.111995</td>\n",
              "      <td>0.113407</td>\n",
              "      <td>0.186809</td>\n",
              "      <td>0.109363</td>\n",
              "      <td>0.283685</td>\n",
              "      <td>0.002290</td>\n",
              "      <td>0.001199</td>\n",
              "      <td>0.001339</td>\n",
              "      <td>0.001771</td>\n",
              "      <td>0.002506</td>\n",
              "      <td>0.001892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.040404</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.620690</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.154144</td>\n",
              "      <td>0.071601</td>\n",
              "      <td>0.106020</td>\n",
              "      <td>0.179863</td>\n",
              "      <td>0.099633</td>\n",
              "      <td>0.275681</td>\n",
              "      <td>0.002290</td>\n",
              "      <td>0.021779</td>\n",
              "      <td>0.011160</td>\n",
              "      <td>0.014493</td>\n",
              "      <td>0.001615</td>\n",
              "      <td>0.001284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>0.212121</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.310345</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.313716</td>\n",
              "      <td>0.249208</td>\n",
              "      <td>0.200746</td>\n",
              "      <td>0.243036</td>\n",
              "      <td>0.111622</td>\n",
              "      <td>0.273259</td>\n",
              "      <td>0.009730</td>\n",
              "      <td>0.011875</td>\n",
              "      <td>0.005583</td>\n",
              "      <td>0.004907</td>\n",
              "      <td>0.011723</td>\n",
              "      <td>0.001892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>0.141414</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.379310</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.148008</td>\n",
              "      <td>0.067955</td>\n",
              "      <td>0.088267</td>\n",
              "      <td>0.168596</td>\n",
              "      <td>0.085794</td>\n",
              "      <td>0.260979</td>\n",
              "      <td>0.002103</td>\n",
              "      <td>0.002094</td>\n",
              "      <td>0.010042</td>\n",
              "      <td>0.000208</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>0.020202</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.275862</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.149674</td>\n",
              "      <td>0.069405</td>\n",
              "      <td>0.087859</td>\n",
              "      <td>0.179805</td>\n",
              "      <td>0.101057</td>\n",
              "      <td>0.275854</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024552</td>\n",
              "      <td>0.006763</td>\n",
              "      <td>0.004689</td>\n",
              "      <td>0.005864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>0.070707</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.344828</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.145064</td>\n",
              "      <td>0.140604</td>\n",
              "      <td>0.128239</td>\n",
              "      <td>0.209850</td>\n",
              "      <td>0.092403</td>\n",
              "      <td>0.298591</td>\n",
              "      <td>0.098334</td>\n",
              "      <td>0.002024</td>\n",
              "      <td>0.001315</td>\n",
              "      <td>0.003101</td>\n",
              "      <td>0.124174</td>\n",
              "      <td>0.003412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>0.040404</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.431034</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.188931</td>\n",
              "      <td>0.112633</td>\n",
              "      <td>0.113667</td>\n",
              "      <td>0.194553</td>\n",
              "      <td>0.112803</td>\n",
              "      <td>0.272746</td>\n",
              "      <td>0.002379</td>\n",
              "      <td>0.001069</td>\n",
              "      <td>0.001596</td>\n",
              "      <td>0.001610</td>\n",
              "      <td>0.002345</td>\n",
              "      <td>0.001892</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 23 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "EIMn8nogObDr",
        "outputId": "0ae22be9-89f0-41ae-88bf-bbe3e842f10a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "X[1]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.11111111e-01, 1.00000000e+00, 3.33333333e-01, 6.66666667e-01,\n",
              "       8.62068966e-02, 1.00000000e-01, 4.00000000e-01, 2.00000000e-01,\n",
              "       2.00000000e-01, 2.00000000e-01, 4.00000000e-01, 1.48892434e-01,\n",
              "       6.78575089e-02, 8.78171337e-02, 1.63219937e-01, 8.40739510e-02,\n",
              "       2.63484742e-01, 0.00000000e+00, 5.93732912e-04, 1.11602161e-03,\n",
              "       1.61030596e-03, 0.00000000e+00, 3.78310691e-03])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-muG2YTObDs",
        "outputId": "5f1a45af-234f-454c-8295-9a0cb99f2a6d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "rpJKepTkObDs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "X[1]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.11111111e-01, 1.00000000e+00, 3.33333333e-01, 6.66666667e-01,\n",
              "       8.62068966e-02, 1.00000000e-01, 4.00000000e-01, 2.00000000e-01,\n",
              "       2.00000000e-01, 2.00000000e-01, 4.00000000e-01, 1.48892434e-01,\n",
              "       6.78575089e-02, 8.78171337e-02, 1.63219937e-01, 8.40739510e-02,\n",
              "       2.63484742e-01, 0.00000000e+00, 5.93732912e-04, 1.11602161e-03,\n",
              "       1.61030596e-03, 0.00000000e+00, 3.78310691e-03])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy8oKwrvObDs",
        "outputId": "c942c280-6034-4a20-fca5-e787359b4a9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Categorical to Numerical Data"
      ],
      "metadata": {
        "id": "u2urUFy9ObDs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "# from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "# #for country column\n",
        "# labelencoder_X_1 = LabelEncoder()\n",
        "# X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
        "# #for gender column\n",
        "# labelencoder_X_2 = LabelEncoder()\n",
        "# X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
        "# np.shape(X)\n",
        "# X"
      ],
      "outputs": [],
      "metadata": {
        "id": "Q7-rzBeEObDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Baseline Model-Using Buildin Function"
      ],
      "metadata": {
        "id": "g1cBuvrnObDt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# # baseline model(using 1 connected layer and one 1 output layer)\n",
        "# def create_baseline():\n",
        "# # create model\n",
        "#     model = Sequential()\n",
        "#     model.add(Dense(30, input_dim=23, kernel_initializer='normal', activation='relu'))\n",
        "#     model.add(Dense(23, input_dim=30, kernel_initializer='normal', activation='relu'))\n",
        "#     model.add(Dense(30, input_dim=23, kernel_initializer='normal', activation='relu'))\n",
        "#     model.add(Dense(30, input_dim=23, kernel_initializer='normal', activation='relu'))\n",
        "#     model.add(Dense(1, kernel_initializer='random_normal', activation='tanh'))\n",
        "#     # Compile model\n",
        "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#     return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "glQf7tE5ObDt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "# seed = 7\n",
        "# numpy.random.seed(seed)\n",
        "# # evaluate model with standardized dataset\n",
        "# estimator = KerasClassifier(build_fn=create_baseline, epochs=50, batch_size=5, verbose=0)\n",
        "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "# results = cross_val_score(estimator, X, y, cv=kfold)\n",
        "# print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "pa_w9j9IObDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Model-Using Sequential Module\n"
      ],
      "metadata": {
        "id": "C3B2vxOWObDu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "X_train"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.04040404e-02, 0.00000000e+00, 3.33333333e-01, ...,\n",
              "        2.42834138e-03, 2.44297574e-03, 0.00000000e+00],\n",
              "       [1.21212121e-01, 0.00000000e+00, 3.33333333e-01, ...,\n",
              "        1.73913043e-03, 0.00000000e+00, 7.37705848e-04],\n",
              "       [2.42424242e-01, 1.00000000e+00, 3.33333333e-01, ...,\n",
              "        7.24798712e-03, 6.61150824e-04, 1.95794698e-02],\n",
              "       ...,\n",
              "       [8.08080808e-02, 1.00000000e+00, 3.33333333e-01, ...,\n",
              "        0.00000000e+00, 1.55909680e-03, 0.00000000e+00],\n",
              "       [3.93939394e-01, 1.00000000e+00, 3.33333333e-01, ...,\n",
              "        1.99033816e-03, 2.80754650e-02, 4.78563025e-04],\n",
              "       [1.71717172e-01, 1.00000000e+00, 5.00000000e-01, ...,\n",
              "        6.37681159e-04, 9.28424562e-04, 7.49055169e-04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if4vA-AWObDu",
        "outputId": "f25ca478-60b2-406a-e851-522c182b0644"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "type(X_train)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQYvbgnwObDu",
        "outputId": "f4f9d310-4246-49aa-9689-761c51dac2be"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "X_train"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.04040404e-02, 0.00000000e+00, 3.33333333e-01, ...,\n",
              "        2.42834138e-03, 2.44297574e-03, 0.00000000e+00],\n",
              "       [1.21212121e-01, 0.00000000e+00, 3.33333333e-01, ...,\n",
              "        1.73913043e-03, 0.00000000e+00, 7.37705848e-04],\n",
              "       [2.42424242e-01, 1.00000000e+00, 3.33333333e-01, ...,\n",
              "        7.24798712e-03, 6.61150824e-04, 1.95794698e-02],\n",
              "       ...,\n",
              "       [8.08080808e-02, 1.00000000e+00, 3.33333333e-01, ...,\n",
              "        0.00000000e+00, 1.55909680e-03, 0.00000000e+00],\n",
              "       [3.93939394e-01, 1.00000000e+00, 3.33333333e-01, ...,\n",
              "        1.99033816e-03, 2.80754650e-02, 4.78563025e-04],\n",
              "       [1.71717172e-01, 1.00000000e+00, 5.00000000e-01, ...,\n",
              "        6.37681159e-04, 9.28424562e-04, 7.49055169e-04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBGXvdy3ObDv",
        "outputId": "c9c03220-e0d0-4ea0-90ec-176b7a7465b3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "y.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzYWSkoKObDv",
        "outputId": "3a4e95f3-a9f6-4f13-bf73-8b092d313aa0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "import tensorflow as tf\n",
        "# import keras\n",
        "# from keras import layers\n",
        "# from keras import models\n",
        "# from keras import utils\n",
        "# from keras.layers import Dense\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Flatten\n",
        "# from keras.layers import Dropout\n",
        "# from keras.layers import Activation\n",
        "# from keras.regularizers import l2\n",
        "# from keras.optimizers import SGD\n",
        "# from keras.optimizers import RMSprop\n",
        "# from keras import datasets\n",
        "\n",
        "# from keras.callbacks import LearningRateScheduler\n",
        "# from keras.callbacks import History\n",
        "\n",
        "# from keras import losses\n",
        "# from sklearn.utils import shuffle\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "print(tf.__version__)\n",
        "print(tf.keras.__version__)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.0\n",
            "2.5.0\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OqG-5K0ObDv",
        "outputId": "64780460-0e45-4ed5-dab9-a6d9d6ad5f55"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-2,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.1)\n",
        "optimizer1 = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
        "optimizer2 = keras.optimizers.Adam(learning_rate = 0.001,beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07)"
      ],
      "outputs": [],
      "metadata": {
        "id": "umggJB7jObDw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{loss:.2f}.h5'),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "]"
      ],
      "outputs": [],
      "metadata": {
        "id": "rNmdczm0ObDw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "# #Initializing Neural Network\n",
        "# Model = keras.Sequential()\n",
        "# Model.add(Dense(100, input_dim = 23, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
        "# # Adding the second hidden layer\n",
        "# Model.add(Dense(200, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
        "# # Adding the third hidden layer\n",
        "# Model.add(Dense(300, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "# # Adding the Fourth hidden layer\n",
        "# Model.add(Dense(200, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
        "# # Adding the Fifth layer\n",
        "# Model.add(Dense(200, kernel_initializer = 'random_uniform', activation = 'relu'))\n",
        "# # Adding the output layer\n",
        "# Model.add(Dense(1, kernel_initializer = 'random_uniform', activation = 'sigmoid'))\n",
        "# # Compiling Neural Network\n",
        "# Model.compile(optimizer = optimizer2, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "# #fitting the neural Network\n",
        "# early_stopping_monitor = EarlyStopping(patience=2)\n",
        "# Model.fit(X_train, y_train, batch_size = 15, epochs = 50)"
      ],
      "outputs": [],
      "metadata": {
        "id": "tdzxJQSsObDw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "# score = Model.evaluate(X_test, y_test, verbose=1)\n",
        "# print('Accuracy: ', score[1]*100)\n",
        "# print( 'loss:', score[0]*100)"
      ],
      "outputs": [],
      "metadata": {
        "id": "I0Cx7Yk-ObDy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "dqTma-vOObDz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "# print(optimizer2.get_weights())"
      ],
      "outputs": [],
      "metadata": {
        "id": "oMeOyKhpObDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Implementation\n",
        "## Import necessary libraries"
      ],
      "metadata": {
        "id": "aRS3HVi4ObD0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "import torch\n",
        "# import keras\n",
        "import numpy\n",
        "import pandas\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "# from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "metadata": {
        "id": "tnwZzp66ObD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process Start"
      ],
      "metadata": {
        "id": "TM56r96DObD0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "X_train"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.04040404e-02, 0.00000000e+00, 3.33333333e-01, ...,\n",
              "        2.42834138e-03, 2.44297574e-03, 0.00000000e+00],\n",
              "       [1.21212121e-01, 0.00000000e+00, 3.33333333e-01, ...,\n",
              "        1.73913043e-03, 0.00000000e+00, 7.37705848e-04],\n",
              "       [2.42424242e-01, 1.00000000e+00, 3.33333333e-01, ...,\n",
              "        7.24798712e-03, 6.61150824e-04, 1.95794698e-02],\n",
              "       ...,\n",
              "       [8.08080808e-02, 1.00000000e+00, 3.33333333e-01, ...,\n",
              "        0.00000000e+00, 1.55909680e-03, 0.00000000e+00],\n",
              "       [3.93939394e-01, 1.00000000e+00, 3.33333333e-01, ...,\n",
              "        1.99033816e-03, 2.80754650e-02, 4.78563025e-04],\n",
              "       [1.71717172e-01, 1.00000000e+00, 5.00000000e-01, ...,\n",
              "        6.37681159e-04, 9.28424562e-04, 7.49055169e-04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VMz4ikLObD0",
        "outputId": "9a6f50aa-67d6-4cae-9709-0de067839ae5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "y_train"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqW5ODZuObD1",
        "outputId": "a1e48878-11b1-4ad4-e578-ab3a393ba00a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "X_test"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.04040404e-02, 0.00000000e+00, 5.00000000e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.21212121e-01, 1.00000000e+00, 1.66666667e-01, ...,\n",
              "        6.92431562e-04, 3.47033848e-02, 8.13367987e-04],\n",
              "       [1.71717172e-01, 1.00000000e+00, 1.66666667e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       ...,\n",
              "       [7.07070707e-02, 0.00000000e+00, 5.00000000e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 4.61539044e-03],\n",
              "       [4.04040404e-02, 0.00000000e+00, 3.33333333e-01, ...,\n",
              "        4.33977456e-03, 6.86377714e-02, 7.56621383e-06],\n",
              "       [2.42424242e-01, 1.00000000e+00, 1.66666667e-01, ...,\n",
              "        0.00000000e+00, 6.91629409e-03, 0.00000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpU6tGArObD1",
        "outputId": "b304f919-227d-4b97-bdfa-ec538cf00fbe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "y_test"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA0tPHxNObD1",
        "outputId": "c843f280-f0ee-4ca7-c10e-d17ac810ee97"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "outputs": [],
      "metadata": {
        "id": "O80NWTcyObD1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "x_data"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2rju_sJObD2",
        "outputId": "f9cda5e9-f873-49fd-8469-a65d66b77148"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert to Tensors"
      ],
      "metadata": {
        "id": "lzFrQl4JObD2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "# X_train = torch.tensor(X_train)"
      ],
      "outputs": [],
      "metadata": {
        "id": "0DNo2zlXObD2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "X_train.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24000, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJNnFbFaObD2",
        "outputId": "89cfe0ae-e9ac-4f92-b534-ab8973b869d3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "source": [
        "y_train"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Pn5t91ObD3",
        "outputId": "e24636d9-4283-4cbd-f117-1602d2fda8b3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "y_test"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuxhOprmObD3",
        "outputId": "71f25c49-eaee-4cd1-950f-e632e5e4bfe8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F"
      ],
      "outputs": [],
      "metadata": {
        "id": "OHPP_Cu5ObD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Empty Cache"
      ],
      "metadata": {
        "id": "AED5tTYlObD3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "uAwmeCCVObD4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "source": [
        "y_train_tens=y_train.astype(float)\n",
        "X_test_tens = X_test.astype(float)\n",
        "y_test_tens = y_test.astype(float)\n",
        "X_train_tens=X_train.astype(float)\n",
        "y_train.shape[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIZEew4EObD4",
        "outputId": "84a4ae8d-9d04-4360-e629-0821b9ad161d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "# import torch\n",
        "\n",
        "# # X=X_iris_tr; Y=Y_iris_tr; X_val=X_iris_val; Y_val=Y_iris_val\n",
        "# # del X, Y, X_val, Y_val\n",
        "\n",
        "# def two_layer_regression_autograd_train(X, Y, X_val, Y_val, lr, nite):\n",
        "\n",
        "#     dtype = torch.float\n",
        "#     device = torch.device(\"cpu\")\n",
        "#     # device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "#     # N is batch size; D_in is input dimension;\n",
        "#     # H is hidden dimension; D_out is output dimension.\n",
        "#     N, D_in, H, D_out = X.shape[0], X.shape[1], 200, Y.shape[0]\n",
        "\n",
        "#     # Setting requires_grad=False indicates that we do not need to compute gradients\n",
        "#     # with respect to these Tensors during the backward pass.\n",
        "#     X = torch.from_numpy(X).float()\n",
        "#     Y = torch.from_numpy(Y).float()\n",
        "#     X_val = torch.from_numpy(X_val).float()\n",
        "#     Y_val = torch.from_numpy(Y_val).float()\n",
        "\n",
        "#     # Create random Tensors for weights.\n",
        "#     # Setting requires_grad=True indicates that we want to compute gradients with\n",
        "#     # respect to these Tensors during the backward pass.\n",
        "#     W1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
        "#     W2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "#     losses_tr, losses_val = list(), list()\n",
        "\n",
        "#     learning_rate = lr\n",
        "#     for t in range(nite):\n",
        "#         # Forward pass: compute predicted y using operations on Tensors; these\n",
        "#         # are exactly the same operations we used to compute the forward pass using\n",
        "#         # Tensors, but we do not need to keep references to intermediate values since\n",
        "#         # we are not implementing the backward pass by hand.\n",
        "#         y_pred = X.mm(W1).clamp(min=0).mm(W2)\n",
        "\n",
        "#         # Compute and print loss using operations on Tensors.\n",
        "#         # Now loss is a Tensor of shape (1,)\n",
        "#         # loss.item() gets the scalar value held in the loss.\n",
        "#         loss = (y_pred - Y).pow(2).sum()\n",
        "\n",
        "#         # Use autograd to compute the backward pass. This call will compute the\n",
        "#         # gradient of loss with respect to all Tensors with requires_grad=True.\n",
        "#         # After this call w1.grad and w2.grad will be Tensors holding the gradient\n",
        "#         # of the loss with respect to w1 and w2 respectively.\n",
        "#         loss.backward()\n",
        "\n",
        "#         # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
        "#         # because weights have requires_grad=True, but we don't need to track this\n",
        "#         # in autograd.\n",
        "#         # An alternative way is to operate on weight.data and weight.grad.data.\n",
        "#         # Recall that tensor.data gives a tensor that shares the storage with\n",
        "#         # tensor, but doesn't track history.\n",
        "#         # You can also use torch.optim.SGD to achieve this.\n",
        "#         with torch.no_grad():\n",
        "#             W1 -= learning_rate * W1.grad\n",
        "#             W2 -= learning_rate * W2.grad\n",
        "\n",
        "#             # Manually zero the gradients after updating weights\n",
        "#             W1.grad.zero_()\n",
        "#             W2.grad.zero_()\n",
        "\n",
        "#             y_pred = X_val.mm(W1).clamp(min=0).mm(W2)\n",
        "\n",
        "#             # Compute and print loss using operations on Tensors.\n",
        "#             # Now loss is a Tensor of shape (1,)\n",
        "#             # loss.item() gets the scalar value held in the loss.\n",
        "#             loss_val = (y_pred - Y).pow(2).sum()\n",
        "\n",
        "#         if t % 10 == 0:\n",
        "#             print(t, loss.item(), loss_val.item())\n",
        "\n",
        "#         losses_tr.append(loss.item())\n",
        "#         losses_val.append(loss_val.item())\n",
        "\n",
        "#     return W1, W2, losses_tr, losses_val\n",
        "\n",
        "# W1, W2, losses_tr, losses_val = two_layer_regression_autograd_train(X=X_train, Y=y_train, X_val=X_test, Y_val=y_test,\n",
        "#                                                                  lr=1e-4, nite=50)\n",
        "# plt.plot(np.arange(len(losses_tr)), losses_tr, \"-b\", np.arange(len(losses_val)), losses_val, \"-r\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "UsgSKqKLObD4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "source": [
        "y_train =torch.tensor(y_train_tens,requires_grad = True) \r\n",
        "X_test  =torch.tensor(X_test_tens  ,requires_grad = True)\r\n",
        "y_test  =torch.tensor(y_test_tens  ,requires_grad = True)\r\n",
        "X_train =torch.tensor(X_train_tens,requires_grad = True) \r\n",
        "print(X_train, y_train.shape[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.0404e-02, 0.0000e+00, 3.3333e-01,  ..., 2.4283e-03, 2.4430e-03,\n",
            "         0.0000e+00],\n",
            "        [1.2121e-01, 0.0000e+00, 3.3333e-01,  ..., 1.7391e-03, 0.0000e+00,\n",
            "         7.3771e-04],\n",
            "        [2.4242e-01, 1.0000e+00, 3.3333e-01,  ..., 7.2480e-03, 6.6115e-04,\n",
            "         1.9579e-02],\n",
            "        ...,\n",
            "        [8.0808e-02, 1.0000e+00, 3.3333e-01,  ..., 0.0000e+00, 1.5591e-03,\n",
            "         0.0000e+00],\n",
            "        [3.9394e-01, 1.0000e+00, 3.3333e-01,  ..., 1.9903e-03, 2.8075e-02,\n",
            "         4.7856e-04],\n",
            "        [1.7172e-01, 1.0000e+00, 5.0000e-01,  ..., 6.3768e-04, 9.2842e-04,\n",
            "         7.4906e-04]], dtype=torch.float64, requires_grad=True) 24000\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_TZCcVSObD5",
        "outputId": "32d622fc-e3b6-4b13-ad44-c596cb413575"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "bhLbtTcISvc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complete Sequential Model and Training with SGD Optimizer"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torch.optim as optim\r\n",
        "\r\n",
        "model = nn.Sequential(nn.Linear(23, 256),\r\n",
        "                      nn.ReLU(),\r\n",
        "                      nn.Linear(256, 64),\r\n",
        "                      nn.ReLU(),\r\n",
        "                      nn.Linear(64, 1),\r\n",
        "                      nn.LogSoftmax(dim=1))\r\n",
        "# Define the loss\r\n",
        "criterion = nn.BCELoss()\r\n",
        "# Optimizers require the parameters to optimize and a learning rate\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\r\n",
        "epochs = 5\r\n",
        "for e in range(epochs):\r\n",
        "    running_loss = 0\r\n",
        "    for i, x in enumerate(X_train):\r\n",
        "        # Flatten MNIST images into a 784 long vector\r\n",
        "        x = x.float()\r\n",
        "        x = x.view(-1,x.shape[0])\r\n",
        "        # Training pass\r\n",
        "        optimizer.zero_grad()\r\n",
        "        y = y_train.view(y_train.shape[0],1)\r\n",
        "        # y = y.type(torch.LongTensor)\r\n",
        "        label = y[i].view(1,1)\r\n",
        "        # label = torch.full((1,1), y[i], dtype=torch.float)\r\n",
        "        label = label.float()\r\n",
        "        output = model(x)\r\n",
        "        # print(output.shape,label.shape)\r\n",
        "        loss = criterion(output, label.detach())\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        running_loss += loss.item()\r\n",
        "    else:\r\n",
        "        print(f\"Training loss: {running_loss/len(y_train)}\")"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZKGhw_mTRorj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "X2OsLDncObD6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "print('Using {} device'.format(device))"
      ],
      "outputs": [],
      "metadata": {
        "id": "9HncBdmLObD6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class NeuralNetwork(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(NeuralNetwork, self).__init__()\r\n",
        "        self.fc1 = nn.Linear(23,200)\r\n",
        "        self.fc2 = nn.Linear(200,300)\r\n",
        "        self.fc3 = nn.Linear(300,1)\r\n",
        "\r\n",
        "        # self.flatten = nn.Flatten()\r\n",
        "        # self.linear_relu_stack = nn.Sequential(\r\n",
        "        #     nn.Linear(23, 200),\r\n",
        "        #     nn.ReLU(),\r\n",
        "        #     nn.Linear(200, 1),\r\n",
        "        #     # nn.ReLU(),\r\n",
        "        #     # nn.Linear(250, 1),\r\n",
        "        #     nn.ReLU()\r\n",
        "        # )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        self.x1 = F.relu(self.fc1(x))\r\n",
        "        self.x2 = F.relu(self.fc2(self.x1))\r\n",
        "        x3 = F.sigmoid(self.fc3(self.x2))\r\n",
        "        return x3\r\n",
        "\r\n",
        "    "
      ],
      "outputs": [],
      "metadata": {
        "id": "g7fA1_L7ObD6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = NeuralNetwork().to(device)\r\n",
        "param = list(model.parameters())\r\n",
        "print(len(list(model.parameters())))\r\n",
        "print(param[0].size())"
      ],
      "outputs": [],
      "metadata": {
        "id": "3ElSF_TVObD6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model"
      ],
      "outputs": [],
      "metadata": {
        "id": "-WtebTokObD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function"
      ],
      "metadata": {
        "id": "Bd8SswENObD7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "logits = model(X_train.float())\r\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\r\n",
        "y_pred = pred_probab.argmax(1)\r\n",
        "# y_pred = y_pred.view(1,-1)\r\n",
        "# print(loss)"
      ],
      "outputs": [],
      "metadata": {
        "id": "sSmIYGxNObD7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "criterion = nn.MSELoss()\r\n",
        "\r\n",
        "loss = criterion(y_pred,y_train.float())\r\n",
        "loss = loss.float()\r\n",
        "loss"
      ],
      "outputs": [],
      "metadata": {
        "id": "MdQRGnWjObD8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.zero_grad()     # zeroes the gradient buffers of all parameters\r\n",
        "\r\n",
        "print('fc1.bias.grad before backward')\r\n",
        "print(model.fc1.bias.grad)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "kMaR57LoObD8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torch.optim as optim\r\n",
        "\r\n",
        "# create your optimizer\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\r\n",
        "\r\n",
        "# in your training loop:\r\n",
        "optimizer.zero_grad()   # zero the gradient buffers\r\n",
        "output = model(X_train.float())\r\n",
        "loss = criterion(output.float(), y_train.float())\r\n",
        "loss.backward()\r\n",
        "optimizer.step()    # Does the update"
      ],
      "outputs": [],
      "metadata": {
        "id": "ckNfKFmGObD8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(X_train.size())\r\n",
        "print(X_test.size())\r\n",
        "print(y_train.size())\r\n",
        "print(y_test.size())"
      ],
      "outputs": [],
      "metadata": {
        "id": "3uaLwWJkObD8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "layer1 = nn.Linear(in_features=23, out_features=200,device=device)\r\n",
        "hidden1 = layer1(X_train.float())\r\n",
        "print(hidden1.size())"
      ],
      "outputs": [],
      "metadata": {
        "id": "-lyFkhBbObD9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\r\n",
        "hidden1 = nn.ReLU()(hidden1)\r\n",
        "print(f\"After ReLU: {hidden1}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "9H3cwjm4ObD9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seq_modules = nn.Sequential(\r\n",
        "    layer1,\r\n",
        "    nn.ReLU(),\r\n",
        "    nn.Linear\r\n",
        "    (\r\n",
        "        200,512,\r\n",
        "    device=device\r\n",
        "    ),\r\n",
        "    nn.ReLU(),\r\n",
        "    nn.Linear\r\n",
        "    (\r\n",
        "        512, 256,\r\n",
        "    device =device\r\n",
        "    ),\r\n",
        "    nn.ReLU(),\r\n",
        "    nn.Linear\r\n",
        "    (\r\n",
        "        256,1,device=device\r\n",
        "    ),\r\n",
        "    nn.Softmax(dim=1))\r\n",
        "# input_image = torch.rand(3,28,28)\r\n",
        "logits = seq_modules(X_train.float())"
      ],
      "outputs": [],
      "metadata": {
        "id": "XkYUDBWNObD9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\r\n",
        "y_train = torch.reshape(y_train, (24000, 1))\r\n",
        "y_train.size()"
      ],
      "outputs": [],
      "metadata": {
        "id": "-eX-iFYDObD9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "softmax = nn.Softmax(dim=1)\r\n",
        "pred_probab = logits\r\n",
        "pred_probab.size()\r\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(pred_probab, y_train.float())\r\n",
        "loss"
      ],
      "outputs": [],
      "metadata": {
        "id": "WeOWpiMvObD-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_train"
      ],
      "outputs": [],
      "metadata": {
        "id": "25T9sizFObD-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pred_probab"
      ],
      "outputs": [],
      "metadata": {
        "id": "swlln-_HObD-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(\"Model structure: \", seq_modules, \"\\n\\n\")\r\n",
        "\r\n",
        "for name, param in seq_modules.named_parameters():\r\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "sS4W8GSTObD_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "inp = torch.eye(5, requires_grad=True)\r\n",
        "out = (inp+1).pow(2)\r\n",
        "out.backward(torch.ones_like(inp), retain_graph=True)\r\n",
        "print(\"First call\\n\", inp.grad)\r\n",
        "out.backward(torch.ones_like(inp), retain_graph=True)\r\n",
        "print(\"\\nSecond call\\n\", inp.grad)\r\n",
        "inp.grad.zero_()\r\n",
        "out.backward(torch.ones_like(inp), retain_graph=True)\r\n",
        "print(\"\\nCall after zeroing gradients\\n\", inp.grad)"
      ],
      "outputs": [],
      "metadata": {
        "id": "7mFf3EAiObD_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "G-susFjoObD_"
      }
    }
  ]
}